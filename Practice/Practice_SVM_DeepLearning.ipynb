{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education</th>\n",
       "      <th>Default_Credit</th>\n",
       "      <th>Housing_Loan</th>\n",
       "      <th>Personal_Loan</th>\n",
       "      <th>Subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>other</td>\n",
       "      <td>married</td>\n",
       "      <td>Primary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>Secondary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>Primary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>Secondary_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>Professional_Education</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age       Job Marital_Status               Education Default_Credit  \\\n",
       "0   56     other        married       Primary_Education             no   \n",
       "1   37  services        married     Secondary_Education             no   \n",
       "2   40     admin        married       Primary_Education             no   \n",
       "3   56  services        married     Secondary_Education             no   \n",
       "4   59     admin        married  Professional_Education             no   \n",
       "\n",
       "  Housing_Loan Personal_Loan Subscribed  \n",
       "0           no            no         no  \n",
       "1          yes            no         no  \n",
       "2           no            no         no  \n",
       "3           no           yes         no  \n",
       "4           no            no         no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "data = os.path.join(\"Resources\",\"bank_telemarketing.csv\")\n",
    "\n",
    "# Import our input dataset\n",
    "tele_df = pd.read_csv(data)\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job               9\n",
       "Marital_Status    3\n",
       "Education         4\n",
       "Default_Credit    2\n",
       "Housing_Loan      2\n",
       "Personal_Loan     2\n",
       "Subscribed        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "tele_cat = tele_df.dtypes[tele_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "tele_df[tele_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_admin</th>\n",
       "      <th>Job_blue-collar</th>\n",
       "      <th>Job_entrepreneur</th>\n",
       "      <th>Job_management</th>\n",
       "      <th>Job_other</th>\n",
       "      <th>Job_retired</th>\n",
       "      <th>Job_self-employed</th>\n",
       "      <th>Job_services</th>\n",
       "      <th>Job_technician</th>\n",
       "      <th>Marital_Status_divorced</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Secondary_Education</th>\n",
       "      <th>Education_Tertiary_Education</th>\n",
       "      <th>Default_Credit_no</th>\n",
       "      <th>Default_Credit_yes</th>\n",
       "      <th>Housing_Loan_no</th>\n",
       "      <th>Housing_Loan_yes</th>\n",
       "      <th>Personal_Loan_no</th>\n",
       "      <th>Personal_Loan_yes</th>\n",
       "      <th>Subscribed_no</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  Job_other  \\\n",
       "0        0.0              0.0               0.0             0.0        1.0   \n",
       "1        0.0              0.0               0.0             0.0        0.0   \n",
       "2        1.0              0.0               0.0             0.0        0.0   \n",
       "3        0.0              0.0               0.0             0.0        0.0   \n",
       "4        1.0              0.0               0.0             0.0        0.0   \n",
       "\n",
       "   Job_retired  Job_self-employed  Job_services  Job_technician  \\\n",
       "0          0.0                0.0           0.0             0.0   \n",
       "1          0.0                0.0           1.0             0.0   \n",
       "2          0.0                0.0           0.0             0.0   \n",
       "3          0.0                0.0           1.0             0.0   \n",
       "4          0.0                0.0           0.0             0.0   \n",
       "\n",
       "   Marital_Status_divorced  ...  Education_Secondary_Education  \\\n",
       "0                      0.0  ...                            0.0   \n",
       "1                      0.0  ...                            1.0   \n",
       "2                      0.0  ...                            0.0   \n",
       "3                      0.0  ...                            1.0   \n",
       "4                      0.0  ...                            0.0   \n",
       "\n",
       "   Education_Tertiary_Education  Default_Credit_no  Default_Credit_yes  \\\n",
       "0                           0.0                1.0                 0.0   \n",
       "1                           0.0                1.0                 0.0   \n",
       "2                           0.0                1.0                 0.0   \n",
       "3                           0.0                1.0                 0.0   \n",
       "4                           0.0                1.0                 0.0   \n",
       "\n",
       "   Housing_Loan_no  Housing_Loan_yes  Personal_Loan_no  Personal_Loan_yes  \\\n",
       "0              1.0               0.0               1.0                0.0   \n",
       "1              0.0               1.0               1.0                0.0   \n",
       "2              1.0               0.0               1.0                0.0   \n",
       "3              1.0               0.0               0.0                1.0   \n",
       "4              1.0               0.0               1.0                0.0   \n",
       "\n",
       "   Subscribed_no  Subscribed_yes  \n",
       "0            1.0             0.0  \n",
       "1            1.0             0.0  \n",
       "2            1.0             0.0  \n",
       "3            1.0             0.0  \n",
       "4            1.0             0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(tele_df[tele_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(tele_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job_admin</th>\n",
       "      <th>Job_blue-collar</th>\n",
       "      <th>Job_entrepreneur</th>\n",
       "      <th>Job_management</th>\n",
       "      <th>Job_other</th>\n",
       "      <th>Job_retired</th>\n",
       "      <th>Job_self-employed</th>\n",
       "      <th>Job_services</th>\n",
       "      <th>Job_technician</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_Secondary_Education</th>\n",
       "      <th>Education_Tertiary_Education</th>\n",
       "      <th>Default_Credit_no</th>\n",
       "      <th>Default_Credit_yes</th>\n",
       "      <th>Housing_Loan_no</th>\n",
       "      <th>Housing_Loan_yes</th>\n",
       "      <th>Personal_Loan_no</th>\n",
       "      <th>Personal_Loan_yes</th>\n",
       "      <th>Subscribed_no</th>\n",
       "      <th>Subscribed_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Job_admin  Job_blue-collar  Job_entrepreneur  Job_management  \\\n",
       "0   56        0.0              0.0               0.0             0.0   \n",
       "1   37        0.0              0.0               0.0             0.0   \n",
       "2   40        1.0              0.0               0.0             0.0   \n",
       "3   56        0.0              0.0               0.0             0.0   \n",
       "4   59        1.0              0.0               0.0             0.0   \n",
       "\n",
       "   Job_other  Job_retired  Job_self-employed  Job_services  Job_technician  \\\n",
       "0        1.0          0.0                0.0           0.0             0.0   \n",
       "1        0.0          0.0                0.0           1.0             0.0   \n",
       "2        0.0          0.0                0.0           0.0             0.0   \n",
       "3        0.0          0.0                0.0           1.0             0.0   \n",
       "4        0.0          0.0                0.0           0.0             0.0   \n",
       "\n",
       "   ...  Education_Secondary_Education  Education_Tertiary_Education  \\\n",
       "0  ...                            0.0                           0.0   \n",
       "1  ...                            1.0                           0.0   \n",
       "2  ...                            0.0                           0.0   \n",
       "3  ...                            1.0                           0.0   \n",
       "4  ...                            0.0                           0.0   \n",
       "\n",
       "   Default_Credit_no  Default_Credit_yes  Housing_Loan_no  Housing_Loan_yes  \\\n",
       "0                1.0                 0.0              1.0               0.0   \n",
       "1                1.0                 0.0              0.0               1.0   \n",
       "2                1.0                 0.0              1.0               0.0   \n",
       "3                1.0                 0.0              1.0               0.0   \n",
       "4                1.0                 0.0              1.0               0.0   \n",
       "\n",
       "   Personal_Loan_no  Personal_Loan_yes  Subscribed_no  Subscribed_yes  \n",
       "0               1.0                0.0            1.0             0.0  \n",
       "1               1.0                0.0            1.0             0.0  \n",
       "2               1.0                0.0            1.0             0.0  \n",
       "3               0.0                1.0            1.0             0.0  \n",
       "4               1.0                0.0            1.0             0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "tele_df = tele_df.merge(encode_df,left_index=True, right_index=True)\n",
    "tele_df = tele_df.drop(tele_cat,1)\n",
    "tele_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove loan status target from features data\n",
    "y = tele_df.Subscribed_yes.values\n",
    "X = tele_df.drop(columns=[\"Subscribed_no\",\"Subscribed_yes\"]).values\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM model\n",
    "svm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM model accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  10\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22857/22857 [==============================] - 1s 33us/sample - loss: 0.4115 - acc: 0.8643\n",
      "Epoch 2/50\n",
      "22857/22857 [==============================] - 1s 28us/sample - loss: 0.3722 - acc: 0.8734\n",
      "Epoch 3/50\n",
      "22857/22857 [==============================] - 1s 28us/sample - loss: 0.3697 - acc: 0.8735\n",
      "Epoch 4/50\n",
      "22857/22857 [==============================] - 1s 29us/sample - loss: 0.3683 - acc: 0.87350s - loss: 0.3666 - a\n",
      "Epoch 5/50\n",
      "22857/22857 [==============================] - 1s 28us/sample - loss: 0.3677 - acc: 0.8735\n",
      "Epoch 6/50\n",
      "22857/22857 [==============================] - 1s 28us/sample - loss: 0.3673 - acc: 0.8735\n",
      "Epoch 7/50\n",
      "22857/22857 [==============================] - 1s 29us/sample - loss: 0.3666 - acc: 0.87340s - loss: 0.3769 - \n",
      "Epoch 8/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3663 - acc: 0.8735\n",
      "Epoch 9/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3661 - acc: 0.8735\n",
      "Epoch 10/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3656 - acc: 0.87360s - loss: 0.3603 - acc:\n",
      "Epoch 11/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3652 - acc: 0.8735\n",
      "Epoch 12/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3653 - acc: 0.8733\n",
      "Epoch 13/50\n",
      "22857/22857 [==============================] - 1s 29us/sample - loss: 0.3649 - acc: 0.8735\n",
      "Epoch 14/50\n",
      "22857/22857 [==============================] - 1s 29us/sample - loss: 0.3648 - acc: 0.8735\n",
      "Epoch 15/50\n",
      "22857/22857 [==============================] - 1s 29us/sample - loss: 0.3645 - acc: 0.8734\n",
      "Epoch 16/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3644 - acc: 0.8735\n",
      "Epoch 17/50\n",
      "22857/22857 [==============================] - 1s 32us/sample - loss: 0.3641 - acc: 0.8736\n",
      "Epoch 18/50\n",
      "22857/22857 [==============================] - 1s 33us/sample - loss: 0.3641 - acc: 0.8737\n",
      "Epoch 19/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3638 - acc: 0.8734\n",
      "Epoch 20/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3636 - acc: 0.8738\n",
      "Epoch 21/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3636 - acc: 0.8736\n",
      "Epoch 22/50\n",
      "22857/22857 [==============================] - 1s 41us/sample - loss: 0.3635 - acc: 0.87350s - loss: 0.3\n",
      "Epoch 23/50\n",
      "22857/22857 [==============================] - 1s 36us/sample - loss: 0.3635 - acc: 0.8737\n",
      "Epoch 24/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3635 - acc: 0.8735\n",
      "Epoch 25/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3631 - acc: 0.8734\n",
      "Epoch 26/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3631 - acc: 0.8738\n",
      "Epoch 27/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3628 - acc: 0.87370s - loss: 0.3642 \n",
      "Epoch 28/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3628 - acc: 0.8737\n",
      "Epoch 29/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3627 - acc: 0.8739\n",
      "Epoch 30/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3624 - acc: 0.8738\n",
      "Epoch 31/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3625 - acc: 0.8739\n",
      "Epoch 32/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3624 - acc: 0.8743\n",
      "Epoch 33/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3622 - acc: 0.8740\n",
      "Epoch 34/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3623 - acc: 0.8740\n",
      "Epoch 35/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3621 - acc: 0.8740\n",
      "Epoch 36/50\n",
      "22857/22857 [==============================] - 1s 35us/sample - loss: 0.3621 - acc: 0.8739\n",
      "Epoch 37/50\n",
      "22857/22857 [==============================] - 1s 32us/sample - loss: 0.3619 - acc: 0.8737\n",
      "Epoch 38/50\n",
      "22857/22857 [==============================] - 1s 32us/sample - loss: 0.3616 - acc: 0.8736\n",
      "Epoch 39/50\n",
      "22857/22857 [==============================] - 1s 32us/sample - loss: 0.3616 - acc: 0.8739\n",
      "Epoch 40/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3618 - acc: 0.8738\n",
      "Epoch 41/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3617 - acc: 0.87410s - loss: 0.3669 \n",
      "Epoch 42/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3614 - acc: 0.8742\n",
      "Epoch 43/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3613 - acc: 0.87390s - loss: 0.3631 -\n",
      "Epoch 44/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3612 - acc: 0.8735\n",
      "Epoch 45/50\n",
      "22857/22857 [==============================] - 1s 31us/sample - loss: 0.3614 - acc: 0.8736\n",
      "Epoch 46/50\n",
      "22857/22857 [==============================] - 1s 33us/sample - loss: 0.3614 - acc: 0.8739\n",
      "Epoch 47/50\n",
      "22857/22857 [==============================] - 1s 29us/sample - loss: 0.3611 - acc: 0.8734\n",
      "Epoch 48/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3610 - acc: 0.8739\n",
      "Epoch 49/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3611 - acc: 0.8736\n",
      "Epoch 50/50\n",
      "22857/22857 [==============================] - 1s 30us/sample - loss: 0.3611 - acc: 0.8736\n",
      "7620/7620 - 0s - loss: 0.3703 - acc: 0.8723\n",
      "Loss: 0.37029976150182287, Accuracy: 0.872309684753418\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) \n",
    "# Evaluate the model using the test data \n",
    "model_loss, model_accurancy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accurancy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
