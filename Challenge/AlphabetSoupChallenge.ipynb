{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data\n",
    "data = os.path.join(\"Resources\", \"charity_data.csv\")\n",
    "\n",
    "# Import our input dataset\n",
    "rawdata_df = pd.read_csv(data)\n",
    "rawdata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34299, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape\n",
    "rawdata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                        int64\n",
       "NAME                      object\n",
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking types\n",
    "rawdata_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this dataset are a number of columns that capture metadata about each organization such as the following:- EIN and NAME—Identification columns:\n",
    "- EIN and NAME—Identification columns\n",
    "- APPLICATION_TYPE—Alphabet Soup application type\n",
    "- AFFILIATION—Affiliated sector of industry\n",
    "- CLASSIFICATION—Government organization classification\n",
    "- USE_CASE—Use case for funding\n",
    "- ORGANIZATION—Organization type\n",
    "- STATUS—Active status\n",
    "- INCOME_AMT—Income classification\n",
    "- SPECIAL_CONSIDERATIONS—Special consideration for application\n",
    "- ASK_AMT—Funding amount requested\n",
    "- IS_SUCCESSFUL—Was the money used effectively\n",
    "\n",
    "Columns to drop as they have no impact on the model:\n",
    "- EIN and NAME—Identification columns\n",
    "- APPLICATION_TYPE—Alphabet Soup application type\n",
    "    > informational data only\n",
    "\n",
    "Data to sort and then drop:\n",
    " - STATUS—Active\n",
    "    > status must be egal to 1 as we are focus on currently active companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION     INCOME_AMT  \\\n",
       "0       Independent          C1000    ProductDev   Association              0   \n",
       "1       Independent          C2000  Preservation  Co-operative         1-9999   \n",
       "2  CompanySponsored          C3000    ProductDev   Association              0   \n",
       "3  CompanySponsored          C2000  Preservation         Trust    10000-24999   \n",
       "4       Independent          C1000     Heathcare         Trust  100000-499999   \n",
       "\n",
       "  SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0                      N     5000              1  \n",
       "1                      N   108590              1  \n",
       "2                      N     5000              0  \n",
       "3                      N     6692              1  \n",
       "4                      N   142590              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the dataset\n",
    "cleandata_df = rawdata_df.loc[rawdata_df[\"STATUS\"]==1]\n",
    "cleandata_df = cleandata_df.drop(columns=[\"EIN\",\"NAME\",\"APPLICATION_TYPE\",\"STATUS\"])\n",
    "\n",
    "cleandata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34294, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape\n",
    "cleandata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking types\n",
    "cleandata_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing/Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat = cleandata_df.dtypes[cleandata_df.dtypes == \"object\"].index.tolist()\n",
    "charity_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "cleandata_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only \"CLASSIFICATION\" columns need to be bucketed as its unique values exceed the commonly used limit of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x216ccb02a88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts\n",
    "classification_counts = rawdata_df.CLASSIFICATION.value_counts()\n",
    "classification_counts.plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the density plot, the most common unique values have more than about 1,500 instances within the dataset. That will be our bucket limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17323\n",
       "C2000     6073\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1882\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace\n",
    "replace_classification = list(classification_counts[classification_counts < 1500].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for classification in replace_classification:\n",
    "    cleandata_df.CLASSIFICATION = cleandata_df.CLASSIFICATION.replace(classification,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "cleandata_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  CLASSIFICATION_C1000  CLASSIFICATION_C1200  \\\n",
       "0                   0.0                   1.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   1.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C2000  CLASSIFICATION_C2100  ...  INCOME_AMT_1-9999  \\\n",
       "0                   0.0                   0.0  ...                0.0   \n",
       "1                   1.0                   0.0  ...                1.0   \n",
       "2                   0.0                   0.0  ...                0.0   \n",
       "3                   1.0                   0.0  ...                0.0   \n",
       "4                   0.0                   0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(cleandata_df[charity_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(charity_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  CLASSIFICATION_C1000  CLASSIFICATION_C1200  \\\n",
       "0                   0.0                   1.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   1.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C2000  CLASSIFICATION_C2100  CLASSIFICATION_C3000  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   1.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   1.0   \n",
       "3                   1.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_Other  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  USE_CASE_Preservation  USE_CASE_ProductDev  \\\n",
       "0             0.0                    0.0                  1.0   \n",
       "1             0.0                    1.0                  0.0   \n",
       "2             0.0                    0.0                  1.0   \n",
       "3             0.0                    1.0                  0.0   \n",
       "4             0.0                    0.0                  0.0   \n",
       "\n",
       "   ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                       1.0                        0.0   \n",
       "1                       0.0                        1.0   \n",
       "2                       1.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0     5000              1                           0.0   \n",
       "1   108590              1                           0.0   \n",
       "2     5000              0                           1.0   \n",
       "3     6692              1                           1.0   \n",
       "4   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  CLASSIFICATION_C1000  \\\n",
       "0                0.0                   0.0                   1.0   \n",
       "1                0.0                   0.0                   0.0   \n",
       "2                0.0                   0.0                   0.0   \n",
       "3                0.0                   0.0                   0.0   \n",
       "4                0.0                   0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C1200  CLASSIFICATION_C2000  CLASSIFICATION_C2100  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   1.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   1.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C3000  CLASSIFICATION_Other  USE_CASE_CommunityServ  \\\n",
       "0                   0.0                   0.0                     0.0   \n",
       "1                   0.0                   0.0                     0.0   \n",
       "2                   1.0                   0.0                     0.0   \n",
       "3                   0.0                   0.0                     0.0   \n",
       "4                   0.0                   0.0                     0.0   \n",
       "\n",
       "   USE_CASE_Heathcare  USE_CASE_Other  USE_CASE_Preservation  \\\n",
       "0                 0.0             0.0                    0.0   \n",
       "1                 0.0             0.0                    1.0   \n",
       "2                 0.0             0.0                    0.0   \n",
       "3                 0.0             0.0                    1.0   \n",
       "4                 1.0             0.0                    0.0   \n",
       "\n",
       "   USE_CASE_ProductDev  ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                  1.0                       1.0                        0.0   \n",
       "1                  0.0                       0.0                        1.0   \n",
       "2                  1.0                       1.0                        0.0   \n",
       "3                  0.0                       0.0                        0.0   \n",
       "4                  0.0                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "encodedata_df = cleandata_df.merge(encode_df,left_index=True, right_index=True)\n",
    "encodedata_df = encodedata_df.drop(charity_cat,1)\n",
    "encodedata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASK_AMT                           int64\n",
       "IS_SUCCESSFUL                     int64\n",
       "AFFILIATION_CompanySponsored    float64\n",
       "AFFILIATION_Family/Parent       float64\n",
       "AFFILIATION_Independent         float64\n",
       "AFFILIATION_National            float64\n",
       "AFFILIATION_Other               float64\n",
       "AFFILIATION_Regional            float64\n",
       "CLASSIFICATION_C1000            float64\n",
       "CLASSIFICATION_C1200            float64\n",
       "CLASSIFICATION_C2000            float64\n",
       "CLASSIFICATION_C2100            float64\n",
       "CLASSIFICATION_C3000            float64\n",
       "CLASSIFICATION_Other            float64\n",
       "USE_CASE_CommunityServ          float64\n",
       "USE_CASE_Heathcare              float64\n",
       "USE_CASE_Other                  float64\n",
       "USE_CASE_Preservation           float64\n",
       "USE_CASE_ProductDev             float64\n",
       "ORGANIZATION_Association        float64\n",
       "ORGANIZATION_Co-operative       float64\n",
       "ORGANIZATION_Corporation        float64\n",
       "ORGANIZATION_Trust              float64\n",
       "INCOME_AMT_0                    float64\n",
       "INCOME_AMT_1-9999               float64\n",
       "INCOME_AMT_10000-24999          float64\n",
       "INCOME_AMT_100000-499999        float64\n",
       "INCOME_AMT_10M-50M              float64\n",
       "INCOME_AMT_1M-5M                float64\n",
       "INCOME_AMT_25000-99999          float64\n",
       "INCOME_AMT_50M+                 float64\n",
       "INCOME_AMT_5M-10M               float64\n",
       "SPECIAL_CONSIDERATIONS_N        float64\n",
       "SPECIAL_CONSIDERATIONS_Y        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking types (final)\n",
    "encodedata_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"IS_SUCCESSFUL\" target from features data\n",
    "y = encodedata_df.IS_SUCCESSFUL\n",
    "X = encodedata_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define, build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6905 - acc: 0.5565\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6853 - acc: 0.5658\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6840 - acc: 0.5680\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6832 - acc: 0.5679\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6833 - acc: 0.5681\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6830 - acc: 0.5677\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6822 - acc: 0.5728\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6821 - acc: 0.5689\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6821 - acc: 0.5700\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6817 - acc: 0.5720\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6821 - acc: 0.5717\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6813 - acc: 0.5718\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6815 - acc: 0.5710\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6812 - acc: 0.5712\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6812 - acc: 0.5721\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6809 - acc: 0.5723\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6809 - acc: 0.5723\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6807 - acc: 0.5741\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6807 - acc: 0.5740\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6805 - acc: 0.5747\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6803 - acc: 0.5739\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6806 - acc: 0.5714\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6803 - acc: 0.57370s - loss: 0.6785\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6802 - acc: 0.5743\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6800 - acc: 0.5723\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6802 - acc: 0.5731\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6799 - acc: 0.5743\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6798 - acc: 0.5736\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6800 - acc: 0.57590s - loss: 0.6793 - acc: 0\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6797 - acc: 0.5741\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6797 - acc: 0.5732\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6795 - acc: 0.5765\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6797 - acc: 0.5752\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6795 - acc: 0.5761\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6796 - acc: 0.5745\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6794 - acc: 0.5750\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6795 - acc: 0.5754\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6794 - acc: 0.5749\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6792 - acc: 0.5765\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6796 - acc: 0.5747\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6791 - acc: 0.5754\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6794 - acc: 0.5758\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6788 - acc: 0.5749\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6792 - acc: 0.5743\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6795 - acc: 0.5745\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6791 - acc: 0.5746\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6792 - acc: 0.5760\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6788 - acc: 0.5770\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6793 - acc: 0.5763\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6787 - acc: 0.5763\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*2\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x221bbd3eb88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x221bce7e2c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8573/8573 - 0s - loss: 0.6852 - acc: 0.5605\n",
      "Loss: 0.6851853318925251, Accuracy: 0.5604805946350098\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/4 Adding more neurons to the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6913 - acc: 0.5521\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6862 - acc: 0.56491s - loss: 0.68\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6850 - acc: 0.5661\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6838 - acc: 0.5682\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6837 - acc: 0.5701\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6830 - acc: 0.5684\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6818 - acc: 0.5712\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6828 - acc: 0.57110s - loss: 0.685\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6822 - acc: 0.5704\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6818 - acc: 0.5716\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6818 - acc: 0.5730\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6815 - acc: 0.5728\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6814 - acc: 0.5737\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6812 - acc: 0.5737\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6815 - acc: 0.5702\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6810 - acc: 0.5723\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6809 - acc: 0.57480s - loss: 0.6820\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6810 - acc: 0.5731\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6806 - acc: 0.5748\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6812 - acc: 0.5739\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6808 - acc: 0.5731\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6801 - acc: 0.572 - 1s 29us/sample - loss: 0.6803 - acc: 0.5728\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6806 - acc: 0.5748\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6805 - acc: 0.5733\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6802 - acc: 0.5727- ETA: 0s - loss: 0.6796 - - 1s 29us/sample - loss: 0.6803 - acc: 0.5724\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6803 - acc: 0.5763\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6803 - acc: 0.5737\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6801 - acc: 0.5746\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6800 - acc: 0.57410s - loss: 0.6814 \n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6798 - acc: 0.5743\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6797 - acc: 0.57590s - loss: 0.6803 - acc: \n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6798 - acc: 0.5751\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6801 - acc: 0.5728\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6797 - acc: 0.57410s - loss: 0.6794 - acc: 0.5\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6795 - acc: 0.5747\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6796 - acc: 0.5753\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6794 - acc: 0.5751\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6795 - acc: 0.5745\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6795 - acc: 0.5754\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6795 - acc: 0.5764\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6789 - acc: 0.5763\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6794 - acc: 0.5765\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6793 - acc: 0.57660s - loss: 0.6795 - acc: 0.575\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6790 - acc: 0.5761\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6790 - acc: 0.5765\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 27us/sample - loss: 0.6791 - acc: 0.5762\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6788 - acc: 0.5759\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 27us/sample - loss: 0.6789 - acc: 0.5759\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6791 - acc: 0.5775\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6789 - acc: 0.5759\n",
      "8573/8573 - 0s - loss: 0.6853 - acc: 0.5618\n",
      "Loss: 0.6852508389545158, Accuracy: 0.5617637038230896\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/4 Adding another hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6896 - acc: 0.5597\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6836 - acc: 0.5687\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6826 - acc: 0.5707\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6819 - acc: 0.5678\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6813 - acc: 0.5724- ETA: 0s - loss: 0.6823  - 1s 31us/sample - loss: 0.6816 - acc: 0.5717\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6812 - acc: 0.57350s - loss: 0.6804 - acc: 0.575 - ETA: 0s - loss: 0.6823 - acc: 0.56 - ETA: 0s - loss: 0.6826 - a\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6813 - acc: 0.5722\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6807 - acc: 0.57270s - loss: 0.6786 - ac\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6809 - acc: 0.5706\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6804 - acc: 0.5737\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6802 - acc: 0.5754\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6799 - acc: 0.5750\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6799 - acc: 0.573 - 1s 31us/sample - loss: 0.6799 - acc: 0.5740\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6797 - acc: 0.5746\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6793 - acc: 0.57541s - loss: 0.672\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6793 - acc: 0.5745\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6789 - acc: 0.5760\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6791 - acc: 0.5765\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6788 - acc: 0.5768\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6786 - acc: 0.5770\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6787 - acc: 0.5758\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6784 - acc: 0.5776\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6782 - acc: 0.5774\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6778 - acc: 0.5783\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6778 - acc: 0.5773\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6777 - acc: 0.5774\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6777 - acc: 0.5775\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6772 - acc: 0.5791\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6773 - acc: 0.57710s - loss: 0.672\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6770 - acc: 0.57871s - loss: 0.67\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6769 - acc: 0.57810s - loss: 0.6765 - acc: 0.57\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6771 - acc: 0.5791\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6766 - acc: 0.5792\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6768 - acc: 0.5786\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6764 - acc: 0.5805\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6764 - acc: 0.5800\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6762 - acc: 0.5806\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6764 - acc: 0.5790\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6760 - acc: 0.5795\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6758 - acc: 0.5805\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6761 - acc: 0.5798\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6757 - acc: 0.5791\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6758 - acc: 0.5808\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6757 - acc: 0.58090s - loss: 0.6751 - acc:\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6754 - acc: 0.5794\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6755 - acc: 0.5809\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6753 - acc: 0.5799\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6747 - acc: 0.580 - 1s 33us/sample - loss: 0.6751 - acc: 0.5793\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6752 - acc: 0.58050s - loss: 0.6756 \n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6749 - acc: 0.58050s - loss: 0.6790 \n",
      "8573/8573 - 0s - loss: 0.6898 - acc: 0.5599\n",
      "Loss: 0.6898039286547943, Accuracy: 0.5598973631858826\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "hidden_nodes_layer2 = len(X_train_scaled[0])\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3/4 Increasing the number of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6885 - acc: 0.5580\n",
      "Epoch 2/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6832 - acc: 0.5647\n",
      "Epoch 3/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6828 - acc: 0.5693\n",
      "Epoch 4/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6819 - acc: 0.57140s - loss: 0.6759 - acc: 0.59 - ETA: 0s - loss: 0.6758 -\n",
      "Epoch 5/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6818 - acc: 0.5716\n",
      "Epoch 6/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6809 - acc: 0.5730\n",
      "Epoch 7/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6810 - acc: 0.5723\n",
      "Epoch 8/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6807 - acc: 0.5733\n",
      "Epoch 9/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6808 - acc: 0.5747\n",
      "Epoch 10/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6799 - acc: 0.5763\n",
      "Epoch 11/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6801 - acc: 0.5749\n",
      "Epoch 12/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6800 - acc: 0.5743\n",
      "Epoch 13/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6797 - acc: 0.57670s - loss: 0.6797 - acc: 0.575\n",
      "Epoch 14/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6797 - acc: 0.57570s - loss: 0.6757 \n",
      "Epoch 15/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6794 - acc: 0.5770\n",
      "Epoch 16/100\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6788 - acc: 0.5771\n",
      "Epoch 17/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6790 - acc: 0.5784\n",
      "Epoch 18/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6786 - acc: 0.5774\n",
      "Epoch 19/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6785 - acc: 0.5776\n",
      "Epoch 20/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6784 - acc: 0.57750s - loss: 0.6762 - acc: 0 - ETA: 0s - loss: 0.6788 - acc: 0. - ETA: 0s - loss: 0.6789 - acc: 0.5\n",
      "Epoch 21/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6784 - acc: 0.5770\n",
      "Epoch 22/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6783 - acc: 0.5783\n",
      "Epoch 23/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6779 - acc: 0.5779\n",
      "Epoch 24/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6776 - acc: 0.57930s - loss: 0.6834\n",
      "Epoch 25/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6778 - acc: 0.5777\n",
      "Epoch 26/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6778 - acc: 0.5798\n",
      "Epoch 27/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6776 - acc: 0.5783\n",
      "Epoch 28/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6775 - acc: 0.5777\n",
      "Epoch 29/100\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6770 - acc: 0.579 - 1s 30us/sample - loss: 0.6773 - acc: 0.5793\n",
      "Epoch 30/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6772 - acc: 0.5788\n",
      "Epoch 31/100\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6767 - acc: 0.5782- ETA: 0s - loss: 0.6742  - 1s 30us/sample - loss: 0.6770 - acc: 0.5775\n",
      "Epoch 32/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6769 - acc: 0.5781\n",
      "Epoch 33/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6768 - acc: 0.57900s - loss: 0.6764 - acc: 0\n",
      "Epoch 34/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6768 - acc: 0.5795\n",
      "Epoch 35/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6766 - acc: 0.57910s - loss: 0.6772 - ac\n",
      "Epoch 36/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6765 - acc: 0.5796\n",
      "Epoch 37/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6765 - acc: 0.5787\n",
      "Epoch 38/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6765 - acc: 0.57990s - loss: 0.6753 - acc: 0. - ETA: 0s - loss: 0.6736 - \n",
      "Epoch 39/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6761 - acc: 0.5792\n",
      "Epoch 40/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6760 - acc: 0.5795\n",
      "Epoch 41/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6762 - acc: 0.5791\n",
      "Epoch 42/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6759 - acc: 0.5805\n",
      "Epoch 43/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6760 - acc: 0.58000s - loss: 0.6755 - acc:\n",
      "Epoch 44/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6758 - acc: 0.58090s - loss: 0.6760 - \n",
      "Epoch 45/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6758 - acc: 0.5801\n",
      "Epoch 46/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6753 - acc: 0.57960s - loss: 0.6734 - a\n",
      "Epoch 47/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6754 - acc: 0.57960s - loss: 0.6765 - acc: 0. - ETA: 0s - loss: 0.6767 - ac\n",
      "Epoch 48/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6756 - acc: 0.5799\n",
      "Epoch 49/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6754 - acc: 0.5817\n",
      "Epoch 50/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6752 - acc: 0.5810\n",
      "Epoch 51/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6750 - acc: 0.5801\n",
      "Epoch 52/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6750 - acc: 0.5812\n",
      "Epoch 53/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6753 - acc: 0.5805\n",
      "Epoch 54/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6749 - acc: 0.5810\n",
      "Epoch 55/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6749 - acc: 0.5802\n",
      "Epoch 56/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6747 - acc: 0.5808\n",
      "Epoch 57/100\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6746 - acc: 0.5813\n",
      "Epoch 58/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6745 - acc: 0.5812\n",
      "Epoch 59/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6745 - acc: 0.5805\n",
      "Epoch 60/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6741 - acc: 0.5815\n",
      "Epoch 61/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6745 - acc: 0.58150s - loss: 0.6726\n",
      "Epoch 62/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6746 - acc: 0.5802\n",
      "Epoch 63/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6742 - acc: 0.5807\n",
      "Epoch 64/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6742 - acc: 0.5817\n",
      "Epoch 65/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6743 - acc: 0.5823\n",
      "Epoch 66/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6739 - acc: 0.5818\n",
      "Epoch 67/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6736 - acc: 0.5814\n",
      "Epoch 68/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6739 - acc: 0.58170s - loss: 0.6737 - acc: 0.58\n",
      "Epoch 69/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6739 - acc: 0.5820\n",
      "Epoch 70/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6739 - acc: 0.5822\n",
      "Epoch 71/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6737 - acc: 0.5817\n",
      "Epoch 72/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6738 - acc: 0.5807\n",
      "Epoch 73/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6734 - acc: 0.5828\n",
      "Epoch 74/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6734 - acc: 0.5822\n",
      "Epoch 75/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6736 - acc: 0.5815\n",
      "Epoch 76/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6736 - acc: 0.5811\n",
      "Epoch 77/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6732 - acc: 0.58140s - loss: 0.6740\n",
      "Epoch 78/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6733 - acc: 0.5820\n",
      "Epoch 79/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6732 - acc: 0.5826\n",
      "Epoch 80/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6730 - acc: 0.58260s - loss: 0.6734 - acc: 0.\n",
      "Epoch 81/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6729 - acc: 0.5819\n",
      "Epoch 82/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6728 - acc: 0.5828\n",
      "Epoch 83/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6732 - acc: 0.5826\n",
      "Epoch 84/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6729 - acc: 0.5826\n",
      "Epoch 85/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6727 - acc: 0.5829\n",
      "Epoch 86/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6727 - acc: 0.5832\n",
      "Epoch 87/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6731 - acc: 0.5817\n",
      "Epoch 88/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6726 - acc: 0.5817\n",
      "Epoch 89/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6733 - acc: 0.5813\n",
      "Epoch 90/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6726 - acc: 0.5820\n",
      "Epoch 91/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6727 - acc: 0.5816\n",
      "Epoch 92/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6733 - acc: 0.5816\n",
      "Epoch 93/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6723 - acc: 0.5826\n",
      "Epoch 94/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6725 - acc: 0.5824\n",
      "Epoch 95/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6728 - acc: 0.5826\n",
      "Epoch 96/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6721 - acc: 0.5829\n",
      "Epoch 97/100\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6727 - acc: 0.582 - 1s 29us/sample - loss: 0.6721 - acc: 0.5835\n",
      "Epoch 98/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6729 - acc: 0.5827\n",
      "Epoch 99/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6722 - acc: 0.5832\n",
      "Epoch 100/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6722 - acc: 0.5831\n",
      "8573/8573 - 0s - loss: 0.6988 - acc: 0.5615\n",
      "Loss: 0.6987903638952855, Accuracy: 0.5615304112434387\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "hidden_nodes_layer2 = len(X_train_scaled[0])\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/4 Removing some noisy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing potential noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0     5000              1                           0.0   \n",
       "1   108590              1                           0.0   \n",
       "2     5000              0                           1.0   \n",
       "3     6692              1                           1.0   \n",
       "4   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  CLASSIFICATION_C1000  \\\n",
       "0                0.0                   0.0                   1.0   \n",
       "1                0.0                   0.0                   0.0   \n",
       "2                0.0                   0.0                   0.0   \n",
       "3                0.0                   0.0                   0.0   \n",
       "4                0.0                   0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C1200  CLASSIFICATION_C2000  CLASSIFICATION_C2100  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   1.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   1.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C3000  CLASSIFICATION_Other  USE_CASE_CommunityServ  \\\n",
       "0                   0.0                   0.0                     0.0   \n",
       "1                   0.0                   0.0                     0.0   \n",
       "2                   1.0                   0.0                     0.0   \n",
       "3                   0.0                   0.0                     0.0   \n",
       "4                   0.0                   0.0                     0.0   \n",
       "\n",
       "   USE_CASE_Heathcare  USE_CASE_Other  USE_CASE_Preservation  \\\n",
       "0                 0.0             0.0                    0.0   \n",
       "1                 0.0             0.0                    1.0   \n",
       "2                 0.0             0.0                    0.0   \n",
       "3                 0.0             0.0                    1.0   \n",
       "4                 1.0             0.0                    0.0   \n",
       "\n",
       "   USE_CASE_ProductDev  ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                  1.0                       1.0                        0.0   \n",
       "1                  0.0                       0.0                        1.0   \n",
       "2                  1.0                       1.0                        0.0   \n",
       "3                  0.0                       0.0                        0.0   \n",
       "4                  0.0                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34289, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedata_bis_df=encodedata_df.copy()\n",
    "encodedata_bis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x221b7bf0848>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking repartion of data by amount asked\n",
    "encodedata_bis_df.plot(y=\"ASK_AMT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASK_AMT\n",
       "(0, 2000000]           33198\n",
       "(2000000, 4000000]       358\n",
       "(4000000, 6000000]       180\n",
       "(6000000, 8000000]       100\n",
       "(8000000, 10000000]       42\n",
       "Name: ASK_AMT, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cut the amount asked by spending ranges.\n",
    "amount_asked=encodedata_bis_df[\"ASK_AMT\"]\n",
    "spending_bins = [0, 2000000, 4000000, 6000000, 8000000, 10000000]\n",
    "group_names = [\"<2M\", \"2M-4M\", \"4M-6M\", \"6M-8M\", \">8M\"]\n",
    "amount_asked.groupby(pd.cut(amount_asked, spending_bins)).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to keep only requests with amount asked below 2M$ as they represent about 97% of the total requests received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33198, 34)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedata_bis_df=encodedata_bis_df.loc[encodedata_bis_df[\"ASK_AMT\"]<=2000000]\n",
    "encodedata_bis_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the train and test data + Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"IS_SUCCESSFUL\" target from features data\n",
    "y_bis = encodedata_bis_df.IS_SUCCESSFUL\n",
    "X_bis = encodedata_bis_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_bis_train, X_bis_test, y_bis_train, y_bis_test = train_test_split(X_bis, y_bis, random_state=42, stratify=y_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_bis_scaler = scaler.fit(X_bis_train)\n",
    "\n",
    "# Scale the data\n",
    "X_bis_train_scaled = X_bis_scaler.transform(X_bis_train)\n",
    "X_bis_test_scaled = X_bis_scaler.transform(X_bis_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define, build, train and evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6891 - acc: 0.5573\n",
      "Epoch 2/100\n",
      "24898/24898 [==============================] - 1s 32us/sample - loss: 0.6843 - acc: 0.5651\n",
      "Epoch 3/100\n",
      "24898/24898 [==============================] - 1s 31us/sample - loss: 0.6828 - acc: 0.5671\n",
      "Epoch 4/100\n",
      "24898/24898 [==============================] - 1s 31us/sample - loss: 0.6825 - acc: 0.5688\n",
      "Epoch 5/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6814 - acc: 0.5719\n",
      "Epoch 6/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6809 - acc: 0.5689\n",
      "Epoch 7/100\n",
      "24898/24898 [==============================] - 1s 32us/sample - loss: 0.6806 - acc: 0.5715\n",
      "Epoch 8/100\n",
      "24898/24898 [==============================] - 1s 32us/sample - loss: 0.6805 - acc: 0.57230s - loss: 0.6805 - acc: 0.572\n",
      "Epoch 9/100\n",
      "24898/24898 [==============================] - 1s 30us/sample - loss: 0.6801 - acc: 0.5725\n",
      "Epoch 10/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6799 - acc: 0.5749\n",
      "Epoch 11/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6797 - acc: 0.5725\n",
      "Epoch 12/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6793 - acc: 0.5750\n",
      "Epoch 13/100\n",
      "24898/24898 [==============================] - 1s 46us/sample - loss: 0.6791 - acc: 0.5743\n",
      "Epoch 14/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6790 - acc: 0.5753\n",
      "Epoch 15/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6784 - acc: 0.5756\n",
      "Epoch 16/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6783 - acc: 0.5762\n",
      "Epoch 17/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6785 - acc: 0.5795\n",
      "Epoch 18/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6779 - acc: 0.5774\n",
      "Epoch 19/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6778 - acc: 0.5777\n",
      "Epoch 20/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6771 - acc: 0.5774\n",
      "Epoch 21/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6776 - acc: 0.5780\n",
      "Epoch 22/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6771 - acc: 0.5772\n",
      "Epoch 23/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6766 - acc: 0.5780\n",
      "Epoch 24/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6767 - acc: 0.5791\n",
      "Epoch 25/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6765 - acc: 0.5786\n",
      "Epoch 26/100\n",
      "24898/24898 [==============================] - 1s 41us/sample - loss: 0.6758 - acc: 0.5782\n",
      "Epoch 27/100\n",
      "24898/24898 [==============================] - 1s 42us/sample - loss: 0.6759 - acc: 0.5799\n",
      "Epoch 28/100\n",
      "24898/24898 [==============================] - 1s 41us/sample - loss: 0.6760 - acc: 0.5780\n",
      "Epoch 29/100\n",
      "24898/24898 [==============================] - 1s 44us/sample - loss: 0.6754 - acc: 0.5809\n",
      "Epoch 30/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6756 - acc: 0.5798\n",
      "Epoch 31/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6748 - acc: 0.5798\n",
      "Epoch 32/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6751 - acc: 0.5809\n",
      "Epoch 33/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6750 - acc: 0.5782\n",
      "Epoch 34/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6749 - acc: 0.5819\n",
      "Epoch 35/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6746 - acc: 0.5815\n",
      "Epoch 36/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6742 - acc: 0.5814\n",
      "Epoch 37/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6741 - acc: 0.5818\n",
      "Epoch 38/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6740 - acc: 0.5821\n",
      "Epoch 39/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6737 - acc: 0.5823\n",
      "Epoch 40/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6736 - acc: 0.5823\n",
      "Epoch 41/100\n",
      "24898/24898 [==============================] - 1s 41us/sample - loss: 0.6733 - acc: 0.5823\n",
      "Epoch 42/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6733 - acc: 0.5823\n",
      "Epoch 43/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6733 - acc: 0.5829\n",
      "Epoch 44/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6727 - acc: 0.5833\n",
      "Epoch 45/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6728 - acc: 0.5841\n",
      "Epoch 46/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6725 - acc: 0.5835\n",
      "Epoch 47/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6724 - acc: 0.5836\n",
      "Epoch 48/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6723 - acc: 0.5847\n",
      "Epoch 49/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6723 - acc: 0.5833\n",
      "Epoch 50/100\n",
      "24898/24898 [==============================] - 1s 43us/sample - loss: 0.6718 - acc: 0.5837\n",
      "Epoch 51/100\n",
      "24898/24898 [==============================] - ETA: 0s - loss: 0.6724 - acc: 0.583 - 1s 41us/sample - loss: 0.6721 - acc: 0.5837\n",
      "Epoch 52/100\n",
      "24898/24898 [==============================] - 1s 40us/sample - loss: 0.6720 - acc: 0.5833\n",
      "Epoch 53/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6715 - acc: 0.5831\n",
      "Epoch 54/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6712 - acc: 0.5842\n",
      "Epoch 55/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6709 - acc: 0.5841\n",
      "Epoch 56/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6709 - acc: 0.58520s - loss: 0.6709 - acc: 0.58\n",
      "Epoch 57/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6710 - acc: 0.5845\n",
      "Epoch 58/100\n",
      "24898/24898 [==============================] - 1s 38us/sample - loss: 0.6706 - acc: 0.5851\n",
      "Epoch 59/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6703 - acc: 0.5854\n",
      "Epoch 60/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6706 - acc: 0.5846\n",
      "Epoch 61/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6703 - acc: 0.5859\n",
      "Epoch 62/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6701 - acc: 0.5856\n",
      "Epoch 63/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6698 - acc: 0.5853\n",
      "Epoch 64/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6698 - acc: 0.58540s - loss: 0.6688 - \n",
      "Epoch 65/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6697 - acc: 0.5852\n",
      "Epoch 66/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6697 - acc: 0.5860\n",
      "Epoch 67/100\n",
      "24898/24898 [==============================] - 1s 40us/sample - loss: 0.6694 - acc: 0.5857\n",
      "Epoch 68/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6691 - acc: 0.5857\n",
      "Epoch 69/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6692 - acc: 0.5857\n",
      "Epoch 70/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6691 - acc: 0.5869\n",
      "Epoch 71/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6688 - acc: 0.5864\n",
      "Epoch 72/100\n",
      "24898/24898 [==============================] - 1s 40us/sample - loss: 0.6689 - acc: 0.5859\n",
      "Epoch 73/100\n",
      "24898/24898 [==============================] - 1s 37us/sample - loss: 0.6686 - acc: 0.5861\n",
      "Epoch 74/100\n",
      "24898/24898 [==============================] - 1s 39us/sample - loss: 0.6689 - acc: 0.5866\n",
      "Epoch 75/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6683 - acc: 0.5863\n",
      "Epoch 76/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6682 - acc: 0.5857\n",
      "Epoch 77/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6683 - acc: 0.5857\n",
      "Epoch 78/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6682 - acc: 0.5864\n",
      "Epoch 79/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6680 - acc: 0.5869\n",
      "Epoch 80/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6677 - acc: 0.5865\n",
      "Epoch 81/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6680 - acc: 0.5881\n",
      "Epoch 82/100\n",
      "24898/24898 [==============================] - 1s 32us/sample - loss: 0.6676 - acc: 0.5870\n",
      "Epoch 83/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6677 - acc: 0.5864\n",
      "Epoch 84/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6681 - acc: 0.5862\n",
      "Epoch 85/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6678 - acc: 0.5881\n",
      "Epoch 86/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6670 - acc: 0.5886\n",
      "Epoch 87/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6670 - acc: 0.5852\n",
      "Epoch 88/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6670 - acc: 0.5874\n",
      "Epoch 89/100\n",
      "24898/24898 [==============================] - 1s 32us/sample - loss: 0.6668 - acc: 0.5867\n",
      "Epoch 90/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6668 - acc: 0.5872\n",
      "Epoch 91/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6667 - acc: 0.5890\n",
      "Epoch 92/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6665 - acc: 0.5888\n",
      "Epoch 93/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6664 - acc: 0.5881\n",
      "Epoch 94/100\n",
      "24898/24898 [==============================] - 1s 33us/sample - loss: 0.6660 - acc: 0.58710s - loss: 0.6651 - acc: 0\n",
      "Epoch 95/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6666 - acc: 0.5890\n",
      "Epoch 96/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6662 - acc: 0.5893\n",
      "Epoch 97/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6663 - acc: 0.5880\n",
      "Epoch 98/100\n",
      "24898/24898 [==============================] - 1s 34us/sample - loss: 0.6656 - acc: 0.5886\n",
      "Epoch 99/100\n",
      "24898/24898 [==============================] - 1s 36us/sample - loss: 0.6658 - acc: 0.5888\n",
      "Epoch 100/100\n",
      "24898/24898 [==============================] - 1s 35us/sample - loss: 0.6655 - acc: 0.5881\n",
      "8300/8300 - 0s - loss: 0.7088 - acc: 0.5708\n",
      "Loss: 0.7087593890098204, Accuracy: 0.5708433985710144\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_bis_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_bis_train_scaled[0])*3\n",
    "hidden_nodes_layer2 = len(X_bis_train_scaled[0])\n",
    "\n",
    "\n",
    "nn_bis = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_bis.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_bis.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_bis.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_bis.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_bis.fit(X_bis_train_scaled, y_bis_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_bis.evaluate(X_bis_test_scaled,y_bis_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
