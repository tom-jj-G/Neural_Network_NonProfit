{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data\n",
    "data = os.path.join(\"Resources\", \"charity_data.csv\")\n",
    "\n",
    "# Import our input dataset\n",
    "rawdata_df = pd.read_csv(data)\n",
    "rawdata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34299, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape\n",
    "rawdata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                        int64\n",
       "NAME                      object\n",
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking types\n",
    "rawdata_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this dataset are a number of columns that capture metadata about each organization such as the following:- EIN and NAME—Identification columns:\n",
    "- EIN and NAME—Identification columns\n",
    "- APPLICATION_TYPE—Alphabet Soup application type\n",
    "- AFFILIATION—Affiliated sector of industry\n",
    "- CLASSIFICATION—Government organization classification\n",
    "- USE_CASE—Use case for funding\n",
    "- ORGANIZATION—Organization type\n",
    "- STATUS—Active status\n",
    "- INCOME_AMT—Income classification\n",
    "- SPECIAL_CONSIDERATIONS—Special consideration for application\n",
    "- ASK_AMT—Funding amount requested\n",
    "- IS_SUCCESSFUL—Was the money used effectively\n",
    "\n",
    "Columns to drop as they have no impact on the model:\n",
    "- EIN and NAME—Identification columns\n",
    "- APPLICATION_TYPE—Alphabet Soup application type\n",
    "    > informational data only\n",
    "\n",
    "Data to sort and then drop:\n",
    " - STATUS—Active\n",
    "    > status must be egal to 1 as we are focus on currently active companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION     INCOME_AMT  \\\n",
       "0       Independent          C1000    ProductDev   Association              0   \n",
       "1       Independent          C2000  Preservation  Co-operative         1-9999   \n",
       "2  CompanySponsored          C3000    ProductDev   Association              0   \n",
       "3  CompanySponsored          C2000  Preservation         Trust    10000-24999   \n",
       "4       Independent          C1000     Heathcare         Trust  100000-499999   \n",
       "\n",
       "  SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0                      N     5000              1  \n",
       "1                      N   108590              1  \n",
       "2                      N     5000              0  \n",
       "3                      N     6692              1  \n",
       "4                      N   142590              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the dataset\n",
    "cleandata_df = rawdata_df.loc[rawdata_df[\"STATUS\"]==1]\n",
    "cleandata_df = cleandata_df.drop(columns=[\"EIN\",\"NAME\",\"APPLICATION_TYPE\",\"STATUS\"])\n",
    "\n",
    "cleandata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34294, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape\n",
    "cleandata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking types\n",
    "cleandata_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing/Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat = cleandata_df.dtypes[cleandata_df.dtypes == \"object\"].index.tolist()\n",
    "charity_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "cleandata_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only \"CLASSIFICATION\" columns need to be bucketed as its unique values exceed the commonly used limit of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a9259b0608>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts\n",
    "classification_counts = rawdata_df.CLASSIFICATION.value_counts()\n",
    "classification_counts.plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the density plot, the most common unique values have more than about 1,500 instances within the dataset. That will be our bucket limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17323\n",
       "C2000     6073\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1882\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace\n",
    "replace_classification = list(classification_counts[classification_counts < 1500].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for classification in replace_classification:\n",
    "    cleandata_df.CLASSIFICATION = cleandata_df.CLASSIFICATION.replace(classification,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "cleandata_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  CLASSIFICATION_C1000  CLASSIFICATION_C1200  \\\n",
       "0                   0.0                   1.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   1.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C2000  CLASSIFICATION_C2100  ...  INCOME_AMT_1-9999  \\\n",
       "0                   0.0                   0.0  ...                0.0   \n",
       "1                   1.0                   0.0  ...                1.0   \n",
       "2                   0.0                   0.0  ...                0.0   \n",
       "3                   1.0                   0.0  ...                0.0   \n",
       "4                   0.0                   0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(cleandata_df[charity_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(charity_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  CLASSIFICATION_C1000  CLASSIFICATION_C1200  \\\n",
       "0                   0.0                   1.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   1.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C2000  CLASSIFICATION_C2100  CLASSIFICATION_C3000  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   1.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   1.0   \n",
       "3                   1.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_Other  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  USE_CASE_Preservation  USE_CASE_ProductDev  \\\n",
       "0             0.0                    0.0                  1.0   \n",
       "1             0.0                    1.0                  0.0   \n",
       "2             0.0                    0.0                  1.0   \n",
       "3             0.0                    1.0                  0.0   \n",
       "4             0.0                    0.0                  0.0   \n",
       "\n",
       "   ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                       1.0                        0.0   \n",
       "1                       0.0                        1.0   \n",
       "2                       1.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0     5000              1                           0.0   \n",
       "1   108590              1                           0.0   \n",
       "2     5000              0                           1.0   \n",
       "3     6692              1                           1.0   \n",
       "4   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  CLASSIFICATION_C1000  \\\n",
       "0                0.0                   0.0                   1.0   \n",
       "1                0.0                   0.0                   0.0   \n",
       "2                0.0                   0.0                   0.0   \n",
       "3                0.0                   0.0                   0.0   \n",
       "4                0.0                   0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C1200  CLASSIFICATION_C2000  CLASSIFICATION_C2100  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   1.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   1.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C3000  CLASSIFICATION_Other  USE_CASE_CommunityServ  \\\n",
       "0                   0.0                   0.0                     0.0   \n",
       "1                   0.0                   0.0                     0.0   \n",
       "2                   1.0                   0.0                     0.0   \n",
       "3                   0.0                   0.0                     0.0   \n",
       "4                   0.0                   0.0                     0.0   \n",
       "\n",
       "   USE_CASE_Heathcare  USE_CASE_Other  USE_CASE_Preservation  \\\n",
       "0                 0.0             0.0                    0.0   \n",
       "1                 0.0             0.0                    1.0   \n",
       "2                 0.0             0.0                    0.0   \n",
       "3                 0.0             0.0                    1.0   \n",
       "4                 1.0             0.0                    0.0   \n",
       "\n",
       "   USE_CASE_ProductDev  ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                  1.0                       1.0                        0.0   \n",
       "1                  0.0                       0.0                        1.0   \n",
       "2                  1.0                       1.0                        0.0   \n",
       "3                  0.0                       0.0                        0.0   \n",
       "4                  0.0                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "encodedata_df = cleandata_df.merge(encode_df,left_index=True, right_index=True)\n",
    "encodedata_df = encodedata_df.drop(charity_cat,1)\n",
    "encodedata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASK_AMT                           int64\n",
       "IS_SUCCESSFUL                     int64\n",
       "AFFILIATION_CompanySponsored    float64\n",
       "AFFILIATION_Family/Parent       float64\n",
       "AFFILIATION_Independent         float64\n",
       "AFFILIATION_National            float64\n",
       "AFFILIATION_Other               float64\n",
       "AFFILIATION_Regional            float64\n",
       "CLASSIFICATION_C1000            float64\n",
       "CLASSIFICATION_C1200            float64\n",
       "CLASSIFICATION_C2000            float64\n",
       "CLASSIFICATION_C2100            float64\n",
       "CLASSIFICATION_C3000            float64\n",
       "CLASSIFICATION_Other            float64\n",
       "USE_CASE_CommunityServ          float64\n",
       "USE_CASE_Heathcare              float64\n",
       "USE_CASE_Other                  float64\n",
       "USE_CASE_Preservation           float64\n",
       "USE_CASE_ProductDev             float64\n",
       "ORGANIZATION_Association        float64\n",
       "ORGANIZATION_Co-operative       float64\n",
       "ORGANIZATION_Corporation        float64\n",
       "ORGANIZATION_Trust              float64\n",
       "INCOME_AMT_0                    float64\n",
       "INCOME_AMT_1-9999               float64\n",
       "INCOME_AMT_10000-24999          float64\n",
       "INCOME_AMT_100000-499999        float64\n",
       "INCOME_AMT_10M-50M              float64\n",
       "INCOME_AMT_1M-5M                float64\n",
       "INCOME_AMT_25000-99999          float64\n",
       "INCOME_AMT_50M+                 float64\n",
       "INCOME_AMT_5M-10M               float64\n",
       "SPECIAL_CONSIDERATIONS_N        float64\n",
       "SPECIAL_CONSIDERATIONS_Y        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking types (final)\n",
    "encodedata_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"IS_SUCCESSFUL\" target from features data\n",
    "y = encodedata_df.IS_SUCCESSFUL\n",
    "X = encodedata_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define, build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\p-d-const127b\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6964 - acc: 0.5565\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6860 - acc: 0.5625\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6855 - acc: 0.5645\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6842 - acc: 0.5707\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6834 - acc: 0.5664\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6829 - acc: 0.5697\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6830 - acc: 0.5678\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6822 - acc: 0.5691\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6819 - acc: 0.5699\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6817 - acc: 0.572 - 1s 29us/sample - loss: 0.6815 - acc: 0.5725\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6813 - acc: 0.5726\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6814 - acc: 0.57210s - loss: 0.6793 \n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6812 - acc: 0.5723\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6810 - acc: 0.5721\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6810 - acc: 0.573 - 1s 29us/sample - loss: 0.6811 - acc: 0.5733\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6810 - acc: 0.5752\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6808 - acc: 0.5739\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6809 - acc: 0.5740\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6806 - acc: 0.5722\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6810 - acc: 0.5733\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6806 - acc: 0.5706\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6802 - acc: 0.5758\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6804 - acc: 0.5736\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6798 - acc: 0.5744\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6802 - acc: 0.5750\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6799 - acc: 0.5750\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6803 - acc: 0.57470s - loss: 0.6802 - acc: 0.575\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6798 - acc: 0.5730\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6798 - acc: 0.5744\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6797 - acc: 0.5747\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6798 - acc: 0.5742\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6797 - acc: 0.5744\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6800 - acc: 0.5741\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6798 - acc: 0.57500s - loss: 0.6798 - acc: 0.574\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6796 - acc: 0.5734\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6792 - acc: 0.5749\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6794 - acc: 0.5755\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6795 - acc: 0.5756\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6796 - acc: 0.5744\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6795 - acc: 0.5744\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6795 - acc: 0.5757\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6794 - acc: 0.5761\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6789 - acc: 0.5761\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6793 - acc: 0.5740\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6789 - acc: 0.5745\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6792 - acc: 0.5742\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6791 - acc: 0.5741\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6791 - acc: 0.5752\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6790 - acc: 0.5756\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6788 - acc: 0.5791\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*2\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a92a2eeb08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a92b421dc8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3zV1f348dc7ewcyIIsRIICBEEDEAShuUBFnS9fXol+tttr226nfb5fa4c/aZbFaWlHbWkcFFBXcC3CxCTuBBLL3zb5JbnJ+f9ybcAk3yU3Izbj3/Xw88si9537GOYzP+54txhiUUkr5Hr+hzoBSSqmhoQFAKaV8lAYApZTyURoAlFLKR2kAUEopH6UBQCmlfJRbAUBElojIYRHJEZF7XXy+WERqRGS34+dnTp/9j4jsF5F9IvKciIQ40mNE5G0RyXb8Hj1wxVJKKdWbXgOAiPgDjwFLgXTgSyKS7uLQzcaY2Y6fBxznJgPfBuYZY2YC/sAKx/H3Au8aY9KAdx3vlVJKDZIAN46ZD+QYY44BiMjzwHLgQB/uESoirUAYUORIXw4sdrx+BvgA+HFPF4qLizMTJ05087ZKKaUAduzYUWGMie+a7k4ASAbynd4XAOe6OO58EdmD/QH/A2PMfmNMoYg8ApwAmoC3jDFvOY4fa4wpBjDGFIvImN4yMnHiRLZv3+5GlpVSSnUQkeOu0t3pAxAXaV3Xj9gJTDDGZAJ/Bl523HQ09m/6qUASEC4iX3U3045r3CEi20Vke3l5eV9OVUop1QN3AkABMM7pfQonm3EAMMbUGmPqHa83AoEiEgdcBuQaY8qNMa3AOuACx2mlIpII4Phd5urmxpjVxph5xph58fGn1WCUUkr1kzsBYBuQJiKpIhKEvRN3g/MBIpIgIuJ4Pd9x3UrsTT/niUiY4/NLgYOO0zYAtzhe3wK8cqaFUUop5b5e+wCMMTYRuRt4E/sonjXGmP0icqfj8yeAm4C7RMSGva1/hbEvM/qZiLyEvYnIBuwCVjsu/RDwoojchj1Q3NyfArS2tlJQUIDVau3P6cNOSEgIKSkpBAYGDnVWlFJeTkbSctDz5s0zXTuBc3NziYyMJDY2FkclZMQyxlBZWUldXR2pqalDnR2llJcQkR3GmHld00f8TGCr1eoVD38AESE2NtZrajNKqeFtxAcAwCse/h28qSxKqeHNKwKAUkp5q6qGFh7adIhj5fUDfm0NAEopNYztybfwxIdHKatrHvBrawBQSqlhbE+BBRGYmRw94NfWADBArrvuOs4++2xmzJjB6tX2ka5vvPEGc+fOJTMzk0svvRSA+vp6Vq5cSUZGBrNmzWLt2rVDmW2l1DCXVVDD5PgIIoLdWbmnbwb+ikPo/lf3c6CodkCvmZ4Uxc+Xzej1uDVr1hATE0NTUxPnnHMOy5cv5/bbb+ejjz4iNTWVqqoqAB588EGio6PJysoCoLq6ekDzq5TyHsYY9hbWsGhKnEeu71UBYCg9+uijrF+/HoD8/HxWr17NhRde2DmePyYmBoB33nmH559/vvO80aN1GwSllGsltVbK65qZlTLwzT/gZQHAnW/qnvDBBx/wzjvv8MknnxAWFsbixYvJzMzk8OHDpx1rjNGhnkopt+wtqAEgI2WUR66vfQADoKamhtGjRxMWFsahQ4f49NNPaW5u5sMPPyQ3NxegswnoiiuuYNWqVZ3nahOQUqo7WQU1+PsJ6YlRHrm+BoABsGTJEmw2G7NmzeKnP/0p5513HvHx8axevZobbriBzMxMvvjFLwLwk5/8hOrqambOnElmZibvv//+EOdeKTVc7SmwMHVsJKFB/h65vlc1AQ2V4OBgNm3a5PKzpUuXnvI+IiKCZ555ZjCypZQawYwxZBXWcGV6gsfuoTUApZQahgqqm7A0tpLhoQ5g0ACglFLDUkcHcKaHOoDBSwLASFrSujfeVBalVP/tLbAQ5O/H1IQIj91jxAeAkJAQKisrveLB2bEfQEhIyFBnRSk1xPYW1DA9MZLgAM90AIMXdAKnpKRQUFCAt2wY37EjmFLKd7W3G/YV1rB8TpJH7zPiA0BgYKDunqWU8iq5lQ3UNduYley59n/wgiYgpZTyNlmODuBZ4zw3Agg0ACil1LCzt6CGkEA/psR7rgMYNAAopdSws7fAwoykaAL8PfuI1gCglFLDiK2tnf1FtR5bAdSZBgCllBpGjpY30NTapgFAKaV8zZ4CCwAZHh4BBBoAlFJqWMkqqCEiOIBJceEev5cGAKWUGkb2FtYwMzkKPz/PbxylAUAppYaJFls7B4trmeXBBeCcaQBQSqlh4khpHS229kHpAAYvWApCKaW6U2hporTW6vKzibHhxIQHDXKOetaxBLSnl4DooAFAKeV1csrq+PN7Oby6p4j2bhYKnp4QyabvLELE823t7soqtDAqLJBxMaGDcj8NAEopr3GktI5H383m9axiQgP9uf3CSZw3KZauj/hPjlby14+OcbC4jvQkz2y43h978mvISI4etKCkAUD5DGMM63cVcuWMBMKD9Z++NzlUUsuj72azMauE8CB/7rxoMrcvmtRtE8+slFE8uSWXDXuKhk0AsLa2caS0jm9MnzRo99ROYOUzDpfW8b0X9/D0x3lDnRU1gA6V1LLsz1v46EgFd188hS0/voQfL5neY/t+THgQi9Li7E1E3bURDbKDxbXY2s2gTADroF+DlM/Iq2gA4PW9xXzr4ilDnBvf0dBs43hlIyW1TRRZrJTUWCmusVJS28TCKfHctXjyGV3/4TcOExroz7vfX0x8ZLDb5y2fncx3X9jNzhPVzJsYc0Z5OFPb86p44LUDiMDscRoAlBpwxysbAThQXEteRQMTB2Gmpa/78Eg59/x7J7VWW2ean8DYqBAC/IXfvnmIC6fGMSOpf8MeP8+t4r1DZfx4yfQ+PfwBLk8fS0igH6/sLhqyAHC0vJ6H3zjEm/tLGRsVzB+/OJuE6MHbEtatACAiS4A/Af7A340xD3X5fDHwCpDrSFpnjHlARKYBLzgdOgn4mTHmjyLyC+B2oGMvx/81xmzsb0GU6k1eZSMhgX5YW9vZuK+Yby7WWoCnGGN4cksuv954kKljI/nNJWkkjgohMTqE+IhgAvz9qGls5eLffcD9Gw7wwjfO63PHpzGGhzYdZGxUMF+/YGKf8xgeHMBlZ43l9axifrYsnUAPL73srKK+mT+9k82/Pz9BSIAfP7hiKrcuTCUsaHC/k/d6NxHxBx4DLgcKgG0issEYc6DLoZuNMdc4JxhjDgOzna5TCKx3OuQPxphHziD/aphqamljT4GF8ybFDnVWOp2oamB6gr3Db2OWBgBPaba18ZP1+/jPjgKWzEjgd1/IdNnpHh0WyA+vnMZ967LYsKeI5bOT+3Sftw+UsvOEhd/ckEFoUP82Tr82M4nX9hazNaeCxdPG9OsaffXK7kL+b/0+mlrb+PL88XznsjTiIvpWexko7oS8+UCOMeaYMaYFeB5Y3o97XQocNcYc78e5aoR5/MOjrFj9KZuzy3s/eJAcr2xkQmwYV2UksK+wlhOOJiE1cMrrmvny3z7jPzsK+PalafzlK3N7HHH1hXnjyEiO5jcbD9HQbOv2uK7a2g2/ffMwk+LDufnslH7n96Jp8USFBLBhd1G/r9EXhZYm7luXxdSxEbz1Pxfy4HUzh+zhD+4FgGQg3+l9gSOtq/NFZI+IbBKRGS4+XwE81yXtbhHZKyJrRGS0e1lWw117u2HtjgIAfvnaQWxt7UOcI/saK0WWJibEhrN0ZiIAG/cV9+tatrZ2fvryPlLve52J957+M/Unm7j73zvZnF0+bEaY9IUxhgdePcCK1Z/0Kf/7i2pYvmoL+4tqWPXlOXzv8qm9Lmjm7yf84tp0Smqt/OWDHLfvtXZnAdll9fzwimlntGtWcIA/S2cm8ub+Eqytbf2+jjuMMfz8lX0YA39aMYfJHt7u0R3uNDi5+hvs+q9iJzDBGFMvIlcBLwNpnRcQCQKuBe5zOudx4EHHtR4EfgfcetrNRe4A7gAYP368G9lVQ+2z3CoKLU1cnZHI61nFPL8tn6+eN2FI81RQ3Ui7gQkxYYyLCSMzJZqNWcXceVHfRqA0NNu457ldvHeojBvnppAy+vQZmxX1zby2t5jX9haTPCqUm85O4eZ5KaSMDhuo4njUs5+dYM1We3feh0fKuXh6700jxysbuOnxTxgVFshLd17AzGT3O3XPnhDDDXOS+dtHuXxh3jgmxPbcOW9tbeOPbx8hc9wolsxMcPs+3Vk+O4kXtufz7sEyrp6VeMbX686b+0t452AZ/3vVdMbFDI9/C+4EgAJgnNP7FOCU+pIxptbp9UYR+YuIxBljKhzJS4GdxphSp+M6X4vI34DXXN3cGLMaWA0wb968kfd1yget3VlARHAAj9ycSUV9M79/+wjLMpOIDg0csjwdr7I390yItf/HW5qRyEObDpFf1ej2f8byumZufXob+4tq+NX1M/nKud0HtZ9ek87bB0p5cXs+j76XzaPvZbNgchwP3ZgxrAPBjuPV3P/qfi6aGs+hklrWbM11KwA88eEx2ozhpbsuIHlU35cxuHfpdN7cX8KDrx3g77ec0+Ox//zkOEU1Vh75QuaAzJg9d1IsYyKDeWV3occCQK21lZ9v2E96YhS3Lkj1yD36w5260zYgTURSHd/kVwAbnA8QkQRx/E2IyHzHdSudDvkSXZp/RMT5T/p6YF/fs6+Gm8YWG5uyirkqI4HQIH9+ek061Y0tPPa++9V7T+ho7+/4dnl1hv2f3yY3m4Fyyuq5/i9bySmr52//Na/Hhz9ASKA/yzKT+Odt57L5Rxfz3UunsuN4NX98J7vfZbA0tvCf7fmsfOpzlv5pM+8fKuv3tVwpq7PyzWd3kBgdyqMr5vDVcyewObuCnLK6ns+rtbJ2RwE3nZ3Sr4c/wJioEL59aRrvHCzj/cPdl6umqZVV7+dw4dR4Lpgc1697deXvJ1wzK4kPDpdT09Q6INfs6ndvHqasrpnf3JDh8Y3e+6LXnBhjbMDdwJvAQeBFY8x+EblTRO50HHYTsE9E9gCPAiuMMQZARMKwjyBa1+XSD4tIlojsBS4G/mdASqSG1Bv7SmhoaePGufaOuZnJ0dw0N4WntuZ2TsQaCnmVDYQF+RMXYZ8dOi4mjIzkaF7PKun13G15Vdz4+MdYW9t44RvncelZY/t075TRYXznsjSun5vMq3uKqGl0/yFT3dDCC9tOcMuaz5n3y3f44Ut7OVJaT3NrGyuf3sb3XtyNpbGlT/lxpbWtnW89u5PaJht//drZRIcF8uVzxxMU4MdTW/N6PHfN1jxs7e3csejMljBYuSCVSXHhPPjqAVpsrvuN/vrhUWqaWvnRldPO6F5dLZ+dREtbO2/uO/3fgzGGF7flc/nvP+RvHx3rc1/BrhPV/OPT49xy/kQyB3GSlzvcGnTqGJ+/sUvaE06vVwGrujm3EThtLKAx5mt9yqkaEdbuLGBcTCjnOE2s+eGV03g9q5jfbDrIX782b0jydaKykfExYac0GSzNSODhNw5TUN3YbbPMG/tK+Pbzu0gZFcrTK+czPrb/zTdfnj+ef392gnW7CljpRjPA4x8c5ZG3DtPWbhgfE8Zti1K5OiORjORoWtraWfVeDn/54Cibsyv41XUzuWLGqe3hxhgOFNeyKauED4+Uc1ZiJLctnMS0hMjT7vWr1w+yLa+aP62YzVmJ9qGysRHBLM9MYt3OQn505XSiw05vwqu1tvLsp8dZmpF4xhPrggL8+OmydFY+tY3fv32EBVNiqbfaqGu22X9bbazZmsu1mUl96mNwx6yUaCbEhrFhTxFfOOdki7elsYX71mWxaV8JSdEh/GrjQZ75JI8fXjmNZbOSeu3kbm1r5751WYyNDOH7V0wd0DwPBJ0JrAZMkaWJj49W8u1L0k75jzEmKoRvLp7MI28d4eOjFQNWde+L41WNTI4/9QF1dUYiD79xmDf2lfDfLr69fnSknHue20lGcjRP3nIOo89w7fiZydFkjhvFs5+d4OsXTOyx/bqszsof3znCgilx/OjKacxIijrl+OAAf75/xTSunJHAD1/ayx3/3MGyzCR+sSydIouVjfuK2ZRVTF5lI/5+QmZKNBv2FPHi9gIWTonjtoWpXDQ1Hj8/Yd3OAp7+OI/bFqaeNhZ/5YJU/rOjgBe2n+COC0/vMH/20xPUNdu4q4+d6d25eNoYLp0+hic+PMoTHx497fPkUaH84IqB/fYPICIsz0xi1fs5lNVaGRMVwidHK/nei7spr2vmx0umc8eFk/jkaCW/3niQ7zy/mye35HLf0rM4f3L3c13WbMnlUEkdT3z1bCJDhq4PrDsaANSAWb+rEGPobP5x9t+LJvHc5/n88rWDvHrPQvwHYb/TDu3thhNVjVzapTNzQmw4M5KieD2r+LQAsCffwp3/2sGUMZE8fet8ogboP+9X5o/nR2v3si2vmvmp3S8/8LePjtHa1s4D187o8Zv1zORoXvnWAh7/4Cir3s9mU1YxtnaDv59wweRYvnHRZK5IH0tsRDDVDS08t+0E//j4OCuf3sak+HCun53MqvdzOG9SDPctnX7a9dOTojg3NYZnPj7OrQtST2m/tra28eSWXBalxQ3oN/I/rJjNzuPVRAQHEBESQERwAJHBgYQH+3u0/fza2Uk8+l4OL+8upLqxlSc+PEpqbDjrv7mADMcOXQvT4njtnoWs31XI7946zJf+9imXTB/DJdPHkBgdQkJ0CEnRoYwKC6Sguok/vHOEy9PHDshoJU/QAKAGhDH2sf/zJ8a4bCYJCfTnx0un8+3ndvHSjny+eM7gDektqbXSYmt3ma+rMhL57ZuHKbI0keTowDxaXs/Kp7cRGxHEMyvPGbCHP8A1mYk8+PoB/v3Z8W4DQEV9M//69ATXzU52q1klKMCP71yWxpUzx/LspyfISI7m8vSxp9VYRocH8c3FU7h90SQ2ZhXz5JZcfvf2ERKjQ1j15bndPlxXLkjlzn/t4J2DpSyZeXLsxrqdhVTUN3PnRbP78CfQu6iQwEGbletsyphI0hOj+PXGQwCsOGccP1uWftryDH5+wo1np3D1rESe2prHXz7I4b0uHfLBAX4EB/jhL8L917qaFjU8aABQA2JXvoVjFQ09jqtfNiuRp7fm8ts3j1BcY6XeaqO++WQbb1NLG9+6ZAoXTY0f0Lx1LAI3Ieb0h2lHANi0r4TbFqZSWmvlv578HAH+ceu5jIka2IW5woICuGFOMs99ns/PlrW4XLL475tzsdrsfxZ9MT0higevm9nrcYH+fiyfncy1mUnsLaghNiKox9mol6ePJWV0KGu25nUGgLZ2w+qPjjIrJZoLemgCGWluuWACj7x1hAeuncHSjJ6HhIYE+nPX4sncceEkyuuaKa5pclrp1L7q6ZKZCZ1fLIYjDQBqQKzdUUBIoB9LM7qv6ooIP182g5ue+Jg/vpNNWJC/vXofEkBESCAnKhv4w9tHBjwAnKiyjz6a4KIGkBoXzlmJUWzMKuamuSn815OfY2ls4fk7zifVQ6uFfvncCTzzyXHW7ijg9gtPbXqqamjhH5/ksWxWksdnioqIW6NS/P2EW86fyK82HmR/UQ0zkqJ5Y18JeZWN/OUrc4fVlopn6ovnjO9z7dTfT0hwNP+MNBoA1Bmztrbx6p4ilsxI6LWjK3PcKPbdfyUBfn6n9QP8ffMxfvn6QQ6V1HYu2jYQ8iobCfSXbr+JXZ2RwCNvHeGrT37GsYp6nl45v7PN1xOmJUQyb8Jo/v35Cf57UeopD9A1W3Jpam3j7j5++/e0L5wzjj+8c4Sntubx25tm2dvH48K5csbwbNtW7hk+MxLUiPXuwTJqrTZudHNRruAAf5edwDfOTSHI34/nP893cVb/nai0D/PsruO5o6q/r6iGP3xxNgumeH6U0lfOG09uRQOfHD05X7KmsZWnP87jqpmJTB17+lDNoRQdGsiNc1PYsLuIDXuKyCqs4Y4LJw1qZ74aeBoA1Blbu7OAhKiQMx7eOTo8iCUzE1i3s2BAF+Y6XtXA+B6We5gcH8Hti1L53c2ZXDMracDu25OlMxMZFRbIs5+d6ExbszWX+mbbsPv23+HrCybS0tbOD/+zlzGRwdwwt2/LN6vhRwOAOiPldc18eKSc6+cmD8i3wRXzx1FrtbExq38rdXZljOF4ZSMTe5nA9X9Xp3ODi+GrnhIS6M9Nc1N4c38J5XXN1FpbWbM1lytnjO2ciDXcTI6P4KKp8bS0tXPrwlSCA/q3Br8aPjQAqDOyflcBbe3G5dj//jh/UiwTY8PcagbanlfFk1tyezymurGVOquN8b2sMDkUvnTueGzthhe35/PM1jzqrDbuuSSt9xOH0HcvS2NRWhxfOVdX5vUG2gms+q2qoYXHPzjKeZNimDJmYEasiAgr5o/noU2HyCmr7/a6NY2t3PXsTirqm7lhTnK3s3SPVzpGAA2T5XedTY6P4PxJsfz7sxM0tNi47KwxA77EwUCbM340/7zt3KHOhhogWgNQ/fbL1w9Q32zjgeW9jz3vixvnphDgJ7yw7US3x/xq4wHK65oxBj4+WtntcSe6LAM93Hz53PEUWpqwNLYO+2//yvtoAFD9sjWngnU7C/nGhZMHfMRKfGQwl6ePZe3OQpptp3cGb8mu4MXtBdxx4SQiQwLYktP9tpPHKxsRYdhswNHVlTMSGBMZzMXT4ofdSpHK+2kTkOoza2sb/7c+i4mxYR4bsbJi/ng27Svhrf2lLMs8OTKnscXGvev2MikunO9dPpW8iga25FR0e528ygYSokIICRyeHZZBAX68es9Cwvq5qblSZ0JrAKrPHns/h7zKRn55XYbHHqyLpsSRPCqU57s0A/32zcMUVDfx0I2zCAn0Z2FaHPlVTZ1t/V11LAM9nI2NChmWK0Uq76c1AC9S09RKTlk9OWV1HCmtJ7usHoCfL0sfsGUFskvreOLDo1w/J5mFaZ6bMOXnJ6w4Zxy/e/sIxysbmBAbzo7j1Tz9cR5fO29C50JqHZO2tuRUuNxL9nhVI5cMwcJiSo0EGgC8wD8+yeOx93MorW3uTAsO8GPKmAgKLU0sX7WVh2+axVW9LG7Vm/Z2w/+uzyI8OICfXH3WGea6dzfPsy8/8MK2fL5zWRo/XruXxKgQfuy0bPGkuHCSokPYkl1x2jaNDc02yuuaz2gTF6W8mQYAL/DkllwiggP4+pJUpo6NIG1MJMmjQ/H3E4osTXzz2Z1889md3Loglfuumk5gP9dUf2F7Ptvyqnn4plnE9rB65EBJiA7hkuljeHF7Ae3Gvi/vUyvPISL45D9bEWHBlDjeOlBKm2Md/A7DfQSQUkNNA8AId6KykeOVjdx/7QxuuWDiaZ8njQrlxW+cz683HmTN1lz2FFh47MtzT1m50BjDweI6Psou5/PcKqJCAkgbG8mUMRGkjYlgfEwYVY0t/GbjQc5NjeFmN9f8GQgrzhnPOwe388SHR7lhTjIXu2jOWZgWx392FLCvsOaUkTQ9LQOtlNIAMOJtdgyB7Kk9PijAj19cO4O5E0Zz79q9XP3oZn5zQwYNLTY+OlLB5uwKKurtzUeT48Oxtrbz8u6ik+f7+xEVGoC1tZ1f35AxqMv/Lp4WT0JUCLb2dn56TbrLY5z7AZwDQMcy0NoEpJRrGgBGuM1HKkgeFcokN9auvzYzifTESO78107u+OcOAGLCg1iUFseitHgWpcUx1rEBSn2zjZyyerJL6xwdy/Vclj7W42vUdxXg78eTX59HgJ9ft7N94yKCOSsxii3ZFXzr4pPDUvMqGxkdFkh0qI6wUcoVDQAjmK2tnY+PVrB0ZqLb38qnjInklW8t4K0DJaQ5tsDzc7GIW0RwALPHjWL2MJicNCOp9+URFk6J5ZmPj9PU0kaoY0z9icrGYbkGkFLDhc4DGMH2FtZQa7WxaGrfhmOGBwdw/ZwUZiZHu3z4j0QL0+yrVH6eV9WZdryqoddVQJXyZRoARrAt2RWIwIIzXIffG8yfGEOQvx9bHbOCW2ztFFY3DctF4JQaLjQAjGCbs8vJSI7utm3cl4QG+XP2hNFszrYHgEJLE+0GbQJSqgcaAEaoOmsru05YWDgI2xeOFAvT4jhYXEtFffPJZaC1CUipbmkAGKE+PVaFrd14dDmGkaZjOOjWnAqdBKaUG3QU0Ai1Jbuc0EB7s4eyy0iOJiokgC3ZFUSGBBIW5E/8IMxYVmqk0hrACLU5u4JzJ8XovqxO/P2ECybHOWoA9o3gB3PSmlIjjQaAEaigupFjFQ0sSosf6qwMOwvT4iiqsfLZsSpt/lGqFxoARqAtjpEui7T9/zQdneJ1zTaXy0MrpU7SANBHnx6rpLTWOqR52JxTwdioYNIGaCN2bzIhNoyU0aEAw34jGKWGmgaAPmhvN6x8aht/fi97yPLQ1m7YmlPBwinx2r7tgoh01gK0CUipnmkA6IPKhhaaWts4UlI/ZHnYX1SDpbGVC/u4/IMvuXpWIuFB/kxPiBrqrCg1rOkw0D4ormkC4EhZHcaYIfkG3jHTdYFOAOvWorR49t1/pdaQlOqFWzUAEVkiIodFJEdE7nXx+WIRqRGR3Y6fnznSpzml7RaRWhH5ruOzGBF5W0SyHb+H/YD2Iou97d/S2EplQ8uQ5GFzdjnpiVHE6fj2HunDX6ne9RoARMQfeAxYCqQDXxIRVztzbDbGzHb8PABgjDnckQacDTQC6x3H3wu8a4xJA951vB/WOmoAANmlg98M1NBsY8fxah39o5QaEO7UAOYDOcaYY8aYFuB5YHk/7nUpcNQYc9zxfjnwjOP1M8B1/bjmoCquOTn6J6esbtDv/1luJa1tRsf/K6UGhDsBIBnId3pf4Ejr6nwR2SMim0RkhovPVwDPOb0fa4wpBnD8Pn2z12GmyNLEhNgwIoIDyC4b/BrA5uwKggP8mDdx2LeWKaVGAHc6gV01ppou73cCE4wx9SJyFfAykNZ5AZEg4Frgvr5mUETuAO4AGD9+fF9PH1DFNVaSokMZHRY06E1AtdZW3tpfyvzUGEICdfkHpdSZc6cGUACMc3qfAhQ5H2CMqTXG1OmE304AABKESURBVDtebwQCRcS5oXopsNMYU+qUVioiiQCO32Wubm6MWW2MmWeMmRcfP7RNH8WWJhJHhZA2JsLtGsDR8npe3Jbf+4E9sLa2cfsz2ymrs3LXRZPP6FpKKdXBnQCwDUgTkVTHN/kVwAbnA0QkQRzDLkRkvuO6lU6HfIlTm39wXOMWx+tbgFf6nv3B09ZuKK1rJik6lLSxEVTUN2Np7H0k0F8/PMqP1u7lWHn/agxt7YbvPL+Lz3KreOTmTC7Q4Z9KqQHSawAwxtiAu4E3gYPAi8aY/SJyp4jc6TjsJmCfiOwBHgVWGGMMgIiEAZcD67pc+iHgchHJdnz+0EAUyFPK65ppazeOGkAkADlu1AJ251sAWLezsM/3NMbwk5ezeHN/KT9fls7y2a66XpRSqn/cmgjmaNbZ2CXtCafXq4BV3ZzbCMS6SK/EPjJoRChyDAFNig5limMNnuyyeuZNjOn2nDpra2dT0fpdhXzv8ql92oT9928f4bnP8/nWxZNZuSD1DHKvlFKn06Ug3FTsmASWOCqE5FGhhAb699oRnFVYgzFw49wUCi1NfHqsssfjnT29NZc/v5fDinPG8YMrpp1R3pVSyhUNAG7qmASWGB2Kn58wZUwE2b3MBeho/vnhldOIDA7gpZ0Fbt3r1T1F3P/aAS5PH8svr5ups1qVUh6hAcBNRRYrYUH+RIXYW83SxkT02gew+4SF1LhwEqJDuHpWIm/sK6Gh2dbjOUfL6/nei7s5Z0IMf/7SHAL89a9IKeUZ+nRxU3FNE4nRIZ3fxqeMjaC4xkqdtdXl8cYYdudbmD1uFAA3np1CY0sbm/aV9Hif/7fpEMEB/jz2lbk63l8p5VEaANxUVGMlaVRo5/veRgKV1Fopq2smMyUagHkTRjMhNoyXdnQ/J+Dz3CreOlDKnRdNIj5SF3tTSnmWBgA3FVvsNYAOaU4jgVzZfcLe/j97vH3ZBhHhhjkpfHqsivyqxtOON8bw640HSYgK4baFkwY6+0opdRoNAG5osbVTXt9MYvTJGsC4mDCCAvy6rQHszrcQ5O/HWYmRnWk3zLWP41+/6/Q5Aa9nFbM738L3rphKaJA2/SilPE8DgBtKa60YA0mjTtYA/P2EyfERZJe6Hgm0K99CelIUwQEnH+bjYsI4b1IM63YW4JgnB0CzrY3/98YhpidEcuPcFM8VRCmlnGgAcEPHMtDONQCg2zWBbG3tZBXUdHYAO7txbgp5lY3sOF7dmfbPT46TX9XEfVedhX8fJooppdSZ0ADgho45AM41ALAHgILqJhpbTh3amV1WT1Nrm8sAsDQjkdBAf9Y65gTUNLby5/dyWJQWx0VTdZ1/pdTg0QDgho6tIE+rAYy1dwQfLWs4Jb1jApirABARHMDSmQm8tqcYa2sbj32QQ621lf+96ixPZF0ppbqlAcANxTVNRIUEEB586tJJJ9cEOrUfYPcJC6PDApkQG+byejeenUJds401W3N5emseN85N4azEKM9kXimluqEBwA1FllPnAHSYEBtOgJ+c1g+wO99C5rhR3S7hcP6kWJKiQ3j4jcP4+cH3r5jqkXwrpVRPNAC4oWMWcFeB/n6kxoWfsihcfbONI2V1Lpt/Ovj5Cdc7hoTetjD1tKYlpZQaDG4tB+3rSmqszEpx/UBPGxvBgaLazvdZBfYVQDN7CAAAX78glaaWdu5aPGVA86qUUu7SGkAvrK1tVDa0kOSiBgAwZUwkJ6oasba2AU4dwN0EjA7xkcH8bFk6EcEag5VSQ0MDQC9KOuYAuOgDAPtQ0HYDx8rtI4F251czMTaM0eFBg5ZHpZTqDw0AvTi5E5jrGkDHUNCOkUDOK4AqpdRwpgGgFyd3AnNdA0iNC8dP7KuCltRYKa1t1gCglBoRNAD04uROYK5rAMEB/kyMtY8E2p1vX96htw5gpZQaDjQA9KKoxkpMeFCPm7N0bA+5y7ECaHqSTupSSg1/GgB60XUfAFfSxkaQV9nIttwqzuqyAqhSSg1XGgB6UVxj7XWiVtqYSNraDTtPWJijzT9KqRFCA0AviixNp60C2lXHmkDgegE4pZQajjQA9KCh2Uat1dZrDWByfAQdy/5oB7BSaqTQaag96G4fgK5Cg/wZNzqMWmsrE7tZAVQppYYbDQA96G4fAFeuykik2dbW7QqgSik13GgA6EFvcwCc3bt0uqezo5RSA0r7AHpQZLEiAmOjeg8ASik10mgA6EFxTRNxEcEEBegfk1LK++iTrQfFNdZuF4FTSqmRTgNAD9yZBKaUUiOVBoBuGGPsy0D0MgRUKaVGKg0A3ai12mhoaSNJawBKKS+lAaAbnUNAtQaglPJSbgUAEVkiIodFJEdE7nXx+WIRqRGR3Y6fnzl9NkpEXhKRQyJyUETOd6T/QkQKnc65auCKdeaK+zAJTCmlRqJeJ4KJiD/wGHA5UABsE5ENxpgDXQ7dbIy5xsUl/gS8YYy5SUSCAOe1Ev5gjHmkn3n3qCI3l4FQSqmRyp0awHwgxxhzzBjTAjwPLHfn4iISBVwIPAlgjGkxxlj6m9nBVGyx4u8njInUAKCU8k7uBIBkIN/pfYEjravzRWSPiGwSkRmOtElAOfCUiOwSkb+LSLjTOXeLyF4RWSMio/tVAg8pqmlibGQw/n66to9Syju5EwBcPQFNl/c7gQnGmEzgz8DLjvQAYC7wuDFmDtAAdPQhPA5MBmYDxcDvXN5c5A4R2S4i28vLy93I7sAotli73QheKaW8gTsBoAAY5/Q+BShyPsAYU2uMqXe83ggEikic49wCY8xnjkNfwh4QMMaUGmPajDHtwN+wNzWdxhiz2hgzzxgzLz4+vg9FOzPFNU0k6CxgpZQXcycAbAPSRCTV0Ym7AtjgfICIJIhjHWQRme+4bqUxpgTIF5FpjkMvBQ44jkt0usT1wL4zKskAMsboMhBKKa/X6yggY4xNRO4G3gT8gTXGmP0icqfj8yeAm4C7RMQGNAErjDEdzUT3AM86gscxYKUj/WERmY29OSkP+MbAFevMVDW00Gxr1yGgSimv5tZ+AI5mnY1d0p5wer0KWNXNubuBeS7Sv9annA6i3fn2gUqT4sN7OVIppUYunQnswrpdhYwOC+SCyXFDnRWllPIYDQBd1FpbeftAKcsyk3QfAKWUV9MnXBebsoppsbVz/RxXUx2UUsp7aADoYt3OQlLjwpk9btRQZ0UppTxKA4CTgupGPsut4vo5yThGtSqllNfSAODkld32+W3a/KOU8gUaAByMMazbWcD8iTGMiwnr/QSllBrhNAA47C2o4Wh5A9fP1W//SinfoAHAYf2uQoIC/LgqI7H3g5VSygtoAABa29p5dU8Rl501hujQwKHOjlJKDQoNAMBHR8qpbGjhhjkpQ50VpZQaNBoAsC/9EBMexEXTBm+5aaWUGmo+HwA6l36YlUigv8//cSilfIjPP/E6l36Yq80/Sinf4vMBYO3OQibFhZOZEj3UWVFKqUHl0wEgv6qRz3XpB6WUj/LpALA1pwKAq2fp2H+llO/x6QBQaGnC308Yr0s/KKV8kG8HgOomEqJCCNDRP0opH+TTT75CSxPJo3Tjd6WUb/LpAFBU00TSqJChzoZSSg0Jnw0Abe2GkhorSVoDUEr5KJ8NAOV1zbS2GQ0ASimf5bMBoNDSBEDyaA0ASinf5LMBoKgjAGgNQCnlo3w+ACRGayewUso3+WwAKLQ0ERUSQGSIbgCjlPJNPhsAiixNJI/WGcBKKd/lswGg0GIlWecAKKV8mM8GgCJLkw4BVUr5NJ8MAPXNNmqaWjUAKKV8mk8GAB0CqpRSPhoAOiaBaQ1AKeXLfDIAaA1AKaV8NAAUVjcR4CfERwYPdVaUUmrIuBUARGSJiBwWkRwRudfF54tFpEZEdjt+fub02SgReUlEDonIQRE535EeIyJvi0i24/fogStWz4osTSSOCsHfT/cBVkr5rl4DgIj4A48BS4F04Esiku7i0M3GmNmOnwec0v8EvGGMmQ5kAgcd6fcC7xpj0oB3He8HRZHFSlK0Nv8opXybOzWA+UCOMeaYMaYFeB5Y7s7FRSQKuBB4EsAY02KMsTg+Xg4843j9DHBdXzJ+JnQnMKWUci8AJAP5Tu8LHGldnS8ie0Rkk4jMcKRNAsqBp0Rkl4j8XUTCHZ+NNcYUAzh+j+lfEfrG1tZOSa1uBKOUUu4EAFcN5abL+53ABGNMJvBn4GVHegAwF3jcGDMHaKCPTT0icoeIbBeR7eXl5X051aWyumba2o3uA6CU8nnuBIACYJzT+xSgyPkAY0ytMabe8XojECgicY5zC4wxnzkOfQl7QAAoFZFEAMfvMlc3N8asNsbMM8bMi4+Pd7NY3SvSOQBKKQW4FwC2AWkikioiQcAKYIPzASKSICLieD3fcd1KY0wJkC8i0xyHXgoccLzeANzieH0L8MoZlcRNnTuB6UJwSikfF9DbAcYYm4jcDbwJ+ANrjDH7ReROx+dPADcBd4mIDWgCVhhjOpqJ7gGedQSPY8BKR/pDwIsichtwArh5AMvVrcLOjWC0BqCU8m29BgDobNbZ2CXtCafXq4BV3Zy7G5jnIr0Se41gUBVZmhgVFkh4sFtFV0opr+VzM4GLLFYdAqqUUvhkANB9AJRSCnwwABRW6yQwpZQCHwsAtdZW6pptJOkIIKWU8q0AcHIZaN0MXimlfDIAaA1AKaV8LAAUVutGMEop1cG3AoDFSpC/H3ERuhGMUkr5VADo2AjGTzeCUUop3wsAuhGMUkrZ+VQAKNRJYEop1clnAkBrWzultVZdBVQppRx8JgCU1lppN+hGMEop5eAzAaDIYgV0IxillOrgMwGg0NIIaABQSqkOPhMAOmsAOgpIKaUAHwoAhZYmYsODCA3yH+qsKKXUsOAzAUD3AVBKqVP5TAAorG7SReCUUsqJTwQAY4zWAJRSqgufCAC1TTYaWtp0FVCllHLiEwGg0KLLQCulVFc+FQC0CUgppU7yiQBQpAFAKaVO4zMBICjAj7iIoKHOilJKDRs+EQBS48K5bnYSIroRjFJKdQgY6gwMhhXzx7Ni/vihzoZSSg0rPlEDUEopdToNAEop5aM0ACillI/SAKCUUj5KA4BSSvkoDQBKKeWjNAAopZSP0gCglFI+SowxQ50Ht4lIOXC8l8PigIpByM5wo+X2LVpu33MmZZ9gjInvmjiiAoA7RGS7MWbeUOdjsGm5fYuW2/d4ouzaBKSUUj5KA4BSSvkobwwAq4c6A0NEy+1btNy+Z8DL7nV9AEoppdzjjTUApZRSbvCaACAiS0TksIjkiMi9Q50fTxKRNSJSJiL7nNJiRORtEcl2/B49lHn0BBEZJyLvi8hBEdkvIt9xpHt12UUkREQ+F5E9jnLf70j36nIDiIi/iOwSkdcc772+zAAikiciWSKyW0S2O9IGvOxeEQBExB94DFgKpANfEpH0oc2VRz0NLOmSdi/wrjEmDXjX8d7b2IDvG2POAs4DvuX4e/b2sjcDlxhjMoHZwBIROQ/vLzfAd4CDTu99ocwdLjbGzHYa+jngZfeKAADMB3KMMceMMS3A88DyIc6TxxhjPgKquiQvB55xvH4GuG5QMzUIjDHFxpidjtd12B8MyXh52Y1dveNtoOPH4OXlFpEU4Grg707JXl3mXgx42b0lACQD+U7vCxxpvmSsMaYY7A9KYMwQ58ejRGQiMAf4DB8ou6MpZDdQBrxtjPGFcv8R+BHQ7pTm7WXuYIC3RGSHiNzhSBvwsnvLnsCudnvX4U1eSkQigLXAd40xtSKu/vq9izGmDZgtIqOA9SIyc6jz5Ekicg1QZozZISKLhzo/Q2CBMaZIRMYAb4vIIU/cxFtqAAXAOKf3KUDREOVlqJSKSCKA43fZEOfHI0QkEPvD/1ljzDpHsk+UHcAYYwE+wN4H5M3lXgBcKyJ52Jt0LxGRf+HdZe5kjCly/C4D1mNv5h7wsntLANgGpIlIqogEASuADUOcp8G2AbjF8foW4JUhzItHiP2r/pPAQWPM750+8uqyi0i845s/IhIKXAYcwovLbYy5zxiTYoyZiP3/83vGmK/ixWXuICLhIhLZ8Rq4AtiHB8ruNRPBROQq7G2G/sAaY8yvhjhLHiMizwGLsa8OWAr8HHgZeBEYD5wAbjbGdO0oHtFEZCGwGcjiZLvw/2LvB/DasovILOydfv7Yv7S9aIx5QERi8eJyd3A0Af3AGHONL5RZRCZh/9YP9mb6fxtjfuWJsntNAFBKKdU33tIEpJRSqo80ACillI/SAKCUUj5KA4BSSvkoDQBKKeWjNAAopZSP0gCglFI+SgOAUkr5qP8PrVNz+o0dEHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8573/8573 - 0s - loss: 0.6857 - acc: 0.5628\n",
      "Loss: 0.6857325335540669, Accuracy: 0.5628134608268738\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/4 Adding more neurons to the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6927 - acc: 0.5508\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6861 - acc: 0.5644\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6848 - acc: 0.56600s - loss: 0.6844 - acc:\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6838 - acc: 0.5670\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6838 - acc: 0.5682\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6824 - acc: 0.5688\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6831 - acc: 0.5706\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6827 - acc: 0.5703\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6818 - acc: 0.5719\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6810 - acc: 0.5700\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6819 - acc: 0.5722\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6814 - acc: 0.5741\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6811 - acc: 0.5711\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6817 - acc: 0.57100s - loss: 0.6817 - acc: 0.571\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6809 - acc: 0.5723\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6810 - acc: 0.5722\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6806 - acc: 0.5713\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6804 - acc: 0.57280s - loss: 0.6\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6811 - acc: 0.57330s - loss: 0.677\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6808 - acc: 0.5747\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6807 - acc: 0.5727\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6805 - acc: 0.57210s - loss: 0.\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6804 - acc: 0.57380s - loss: 0.6798 - acc: 0.\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6802 - acc: 0.5735\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6802 - acc: 0.5728\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6805 - acc: 0.5738\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6800 - acc: 0.57410s - loss: 0.677\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6799 - acc: 0.57440s - loss: 0.6783 - ac\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6802 - acc: 0.5759\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6799 - acc: 0.57470s - loss: 0.6\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6798 - acc: 0.5757\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6796 - acc: 0.5747\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6797 - acc: 0.5749\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6798 - acc: 0.5743\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6796 - acc: 0.5739\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6795 - acc: 0.5758\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6794 - acc: 0.5766\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6794 - acc: 0.57470s - loss: 0.6771 - acc: 0.586 - ETA: 0s - loss: 0.6732 - a - ETA: 0s - loss: 0.6796 - acc: 0\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6794 - acc: 0.5743\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6792 - acc: 0.5753\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6795 - acc: 0.5748\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6795 - acc: 0.5763\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6795 - acc: 0.5751\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6795 - acc: 0.5745\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6792 - acc: 0.5723\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6791 - acc: 0.5751\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6793 - acc: 0.5756\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6792 - acc: 0.5748\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6790 - acc: 0.5762\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6791 - acc: 0.5751\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/4 Adding another hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6888 - acc: 0.5553\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6843 - acc: 0.5658\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6832 - acc: 0.5680\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6822 - acc: 0.5713\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6820 - acc: 0.5723\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6813 - acc: 0.5697\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6813 - acc: 0.5716\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6809 - acc: 0.5731\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6807 - acc: 0.5724\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6807 - acc: 0.5753\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6806 - acc: 0.574 - 1s 31us/sample - loss: 0.6803 - acc: 0.5744\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6800 - acc: 0.5739\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6796 - acc: 0.5761\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6799 - acc: 0.5758\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6799 - acc: 0.5756\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6795 - acc: 0.57650s - loss: 0.673\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6791 - acc: 0.5759\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6795 - acc: 0.5756\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6792 - acc: 0.5759\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6790 - acc: 0.5769- ETA: 0s - loss: 0.6776 - 1s 31us/sample - loss: 0.6790 - acc: 0.5774\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6788 - acc: 0.5772\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6787 - acc: 0.5770\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6787 - acc: 0.57690s - loss: 0.6791 \n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6784 - acc: 0.57620s - loss: 0.6785\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6785 - acc: 0.5782\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6783 - acc: 0.5773\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6782 - acc: 0.57890s - loss: 0.675\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6781 - acc: 0.5779\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6780 - acc: 0.5787\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6778 - acc: 0.57780s - loss: 0.6772 - acc: 0.57\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6775 - acc: 0.57840s - loss: 0.676\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6781 - acc: 0.5799\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6776 - acc: 0.57870s - loss: 0.6787 - acc: 0. - ETA: 0s - loss: 0.6778 - acc: 0.57\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6772 - acc: 0.5792\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6775 - acc: 0.5784\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6772 - acc: 0.5785\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6772 - acc: 0.5796\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6771 - acc: 0.5791\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6772 - acc: 0.58030s - loss: 0.6736 - acc: 0.5 - ETA: 0s - loss: 0.6768 - a\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6766 - acc: 0.5795\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6769 - acc: 0.57980s - loss: 0.6764 - a\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6765 - acc: 0.5795\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6767 - acc: 0.5791\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6765 - acc: 0.5796\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6763 - acc: 0.5795\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6762 - acc: 0.5799\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6764 - acc: 0.5796\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6762 - acc: 0.5794\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6759 - acc: 0.58020s - loss: 0.6751 - acc: 0.5\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6762 - acc: 0.5800\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "hidden_nodes_layer2 = len(X_train_scaled[0])\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3/4 Increasing the number of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6909 - acc: 0.55530s - loss: 0.6912 - acc: 0.5\n",
      "Epoch 2/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6847 - acc: 0.5640\n",
      "Epoch 3/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6836 - acc: 0.5679\n",
      "Epoch 4/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6825 - acc: 0.56960s - loss: 0.6825 - acc: 0.56\n",
      "Epoch 5/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6819 - acc: 0.57270s - loss: 0.6797 - acc - ETA: 0s - loss: 0.6806 - acc:\n",
      "Epoch 6/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6821 - acc: 0.5709\n",
      "Epoch 7/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6815 - acc: 0.5725\n",
      "Epoch 8/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6813 - acc: 0.5709\n",
      "Epoch 9/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6809 - acc: 0.5727\n",
      "Epoch 10/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6808 - acc: 0.5721\n",
      "Epoch 11/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6807 - acc: 0.5726\n",
      "Epoch 12/100\n",
      "25716/25716 [==============================] - 1s 28us/sample - loss: 0.6803 - acc: 0.5740\n",
      "Epoch 13/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6801 - acc: 0.5754\n",
      "Epoch 14/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6802 - acc: 0.5751\n",
      "Epoch 15/100\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6800 - acc: 0.5758\n",
      "Epoch 16/100\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6798 - acc: 0.5764\n",
      "Epoch 17/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6795 - acc: 0.5761\n",
      "Epoch 18/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6793 - acc: 0.57680s - loss: 0.6778 - acc\n",
      "Epoch 19/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6792 - acc: 0.57690s - loss: 0.6784 - ac\n",
      "Epoch 20/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6790 - acc: 0.5767\n",
      "Epoch 21/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6792 - acc: 0.5773\n",
      "Epoch 22/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6786 - acc: 0.57820s - loss: 0.6786 - acc: 0. - ETA: 0s - loss: 0.6789 - acc: 0. - ETA: 0s - loss: 0.6787 - acc: 0.578\n",
      "Epoch 23/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6786 - acc: 0.5778\n",
      "Epoch 24/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6785 - acc: 0.5775\n",
      "Epoch 25/100\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6779 - acc: 0.5784\n",
      "Epoch 26/100\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6778 - acc: 0.5780\n",
      "Epoch 27/100\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6781 - acc: 0.5768\n",
      "Epoch 28/100\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6778 - acc: 0.5782\n",
      "Epoch 29/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6776 - acc: 0.5782\n",
      "Epoch 30/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6775 - acc: 0.5782\n",
      "Epoch 31/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6774 - acc: 0.57870s - loss: 0.6775 - ac\n",
      "Epoch 32/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6771 - acc: 0.5784\n",
      "Epoch 33/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6769 - acc: 0.57830s - loss: 0.6773 - acc:  - ETA: 0s - loss: 0.6771 - acc:\n",
      "Epoch 34/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6769 - acc: 0.5784\n",
      "Epoch 35/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6767 - acc: 0.58000s - loss: 0.6782 - acc\n",
      "Epoch 36/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6769 - acc: 0.5792\n",
      "Epoch 37/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6767 - acc: 0.5781\n",
      "Epoch 38/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6765 - acc: 0.5789\n",
      "Epoch 39/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6763 - acc: 0.5799\n",
      "Epoch 40/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6761 - acc: 0.5800\n",
      "Epoch 41/100\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6762 - acc: 0.5811\n",
      "Epoch 42/100\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6757 - acc: 0.5798\n",
      "Epoch 43/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6759 - acc: 0.5806\n",
      "Epoch 44/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6757 - acc: 0.5796\n",
      "Epoch 45/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6757 - acc: 0.5784\n",
      "Epoch 46/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6756 - acc: 0.58050s - loss: 0.6759 - acc:\n",
      "Epoch 47/100\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6756 - acc: 0.5785- ETA: 0s - loss: 0.674 - 1s 32us/sample - loss: 0.6755 - acc: 0.5792\n",
      "Epoch 48/100\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6754 - acc: 0.5786\n",
      "Epoch 49/100\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6752 - acc: 0.5799\n",
      "Epoch 50/100\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6749 - acc: 0.5805\n",
      "Epoch 51/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6750 - acc: 0.5796\n",
      "Epoch 52/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6751 - acc: 0.5802\n",
      "Epoch 53/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6748 - acc: 0.5819\n",
      "Epoch 54/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6746 - acc: 0.5799\n",
      "Epoch 55/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6744 - acc: 0.5819\n",
      "Epoch 56/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6748 - acc: 0.58170s - loss: 0.67\n",
      "Epoch 57/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6744 - acc: 0.5806\n",
      "Epoch 58/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6744 - acc: 0.58020s - loss: 0.6743 \n",
      "Epoch 59/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6741 - acc: 0.5814\n",
      "Epoch 60/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6742 - acc: 0.5805\n",
      "Epoch 61/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6744 - acc: 0.5795\n",
      "Epoch 62/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6738 - acc: 0.5805\n",
      "Epoch 63/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6741 - acc: 0.58060s - loss: 0.6767 \n",
      "Epoch 64/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6741 - acc: 0.5812\n",
      "Epoch 65/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6738 - acc: 0.5811\n",
      "Epoch 66/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6739 - acc: 0.5817\n",
      "Epoch 67/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6736 - acc: 0.5818\n",
      "Epoch 68/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6739 - acc: 0.58110s - loss: 0.6735 - acc: 0.581\n",
      "Epoch 69/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6734 - acc: 0.5808\n",
      "Epoch 70/100\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6737 - acc: 0.5810\n",
      "Epoch 71/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6738 - acc: 0.58050s - loss: 0.6747 - acc:\n",
      "Epoch 72/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6736 - acc: 0.57970s - loss: 0.6762 \n",
      "Epoch 73/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6735 - acc: 0.5804\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6737 - acc: 0.58150s - loss: 0.6735 - \n",
      "Epoch 75/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6731 - acc: 0.5814\n",
      "Epoch 76/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6732 - acc: 0.5813\n",
      "Epoch 77/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6734 - acc: 0.5804\n",
      "Epoch 78/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6732 - acc: 0.5812\n",
      "Epoch 79/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6731 - acc: 0.5812\n",
      "Epoch 80/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6730 - acc: 0.58200s - loss: 0.6757\n",
      "Epoch 81/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6728 - acc: 0.5810\n",
      "Epoch 82/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6729 - acc: 0.58160s - loss: 0.6724\n",
      "Epoch 83/100\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6730 - acc: 0.581 - 1s 31us/sample - loss: 0.6730 - acc: 0.5815\n",
      "Epoch 84/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6728 - acc: 0.5822\n",
      "Epoch 85/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6727 - acc: 0.5826\n",
      "Epoch 86/100\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6728 - acc: 0.5810\n",
      "Epoch 87/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6735 - acc: 0.5819\n",
      "Epoch 88/100\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6732 - acc: 0.5814\n",
      "Epoch 89/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6724 - acc: 0.58220s - loss: 0.6723 -\n",
      "Epoch 90/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6728 - acc: 0.58200s - loss: 0.6731 - acc: 0.5\n",
      "Epoch 91/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6726 - acc: 0.5814\n",
      "Epoch 92/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6725 - acc: 0.5823\n",
      "Epoch 93/100\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6728 - acc: 0.5816\n",
      "Epoch 94/100\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6722 - acc: 0.5829\n",
      "Epoch 95/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6733 - acc: 0.5817\n",
      "Epoch 96/100\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6728 - acc: 0.5817\n",
      "Epoch 97/100\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6720 - acc: 0.58220s - loss: 0.6726 - a\n",
      "Epoch 98/100\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6722 - acc: 0.5833\n",
      "Epoch 99/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6722 - acc: 0.5819\n",
      "Epoch 100/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6722 - acc: 0.58160s - loss: 0.6704 - \n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "hidden_nodes_layer2 = len(X_train_scaled[0])\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/4 Removing some noisy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing potential noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0     5000              1                           0.0   \n",
       "1   108590              1                           0.0   \n",
       "2     5000              0                           1.0   \n",
       "3     6692              1                           1.0   \n",
       "4   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  CLASSIFICATION_C1000  \\\n",
       "0                0.0                   0.0                   1.0   \n",
       "1                0.0                   0.0                   0.0   \n",
       "2                0.0                   0.0                   0.0   \n",
       "3                0.0                   0.0                   0.0   \n",
       "4                0.0                   0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C1200  CLASSIFICATION_C2000  CLASSIFICATION_C2100  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   1.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   1.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C3000  CLASSIFICATION_Other  USE_CASE_CommunityServ  \\\n",
       "0                   0.0                   0.0                     0.0   \n",
       "1                   0.0                   0.0                     0.0   \n",
       "2                   1.0                   0.0                     0.0   \n",
       "3                   0.0                   0.0                     0.0   \n",
       "4                   0.0                   0.0                     0.0   \n",
       "\n",
       "   USE_CASE_Heathcare  USE_CASE_Other  USE_CASE_Preservation  \\\n",
       "0                 0.0             0.0                    0.0   \n",
       "1                 0.0             0.0                    1.0   \n",
       "2                 0.0             0.0                    0.0   \n",
       "3                 0.0             0.0                    1.0   \n",
       "4                 1.0             0.0                    0.0   \n",
       "\n",
       "   USE_CASE_ProductDev  ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                  1.0                       1.0                        0.0   \n",
       "1                  0.0                       0.0                        1.0   \n",
       "2                  1.0                       1.0                        0.0   \n",
       "3                  0.0                       0.0                        0.0   \n",
       "4                  0.0                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete=[\"AFFILIATION_CompanySponsored\",\"AFFILIATION_Family/Parent\",\"AFFILIATION_Independent\",\"AFFILIATION_National\",\"AFFILIATION_Other\",\"AFFILIATION_Regional\",\"CLASSIFICATION_C1000\",\"CLASSIFICATION_C1200\",\"CLASSIFICATION_C2000\",\"CLASSIFICATION_C2100\",\"CLASSIFICATION_C3000\",\"CLASSIFICATION_Other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0     5000              1                     0.0                 0.0   \n",
       "1   108590              1                     0.0                 0.0   \n",
       "2     5000              0                     0.0                 0.0   \n",
       "3     6692              1                     0.0                 0.0   \n",
       "4   142590              1                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  USE_CASE_Preservation  USE_CASE_ProductDev  \\\n",
       "0             0.0                    0.0                  1.0   \n",
       "1             0.0                    1.0                  0.0   \n",
       "2             0.0                    0.0                  1.0   \n",
       "3             0.0                    1.0                  0.0   \n",
       "4             0.0                    0.0                  0.0   \n",
       "\n",
       "   ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                       1.0                        0.0   \n",
       "1                       0.0                        1.0   \n",
       "2                       1.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedata_bis_df=encodedata_df.drop(columns=columns_to_delete)\n",
    "encodedata_bis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the train and test data + Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"IS_SUCCESSFUL\" target from features data\n",
    "y_bis = encodedata_df.IS_SUCCESSFUL\n",
    "X_bis = encodedata_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_bis_train, X_bis_test, y_bis_train, y_bis_test = train_test_split(X_bis, y_bis, random_state=42, stratify=y_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler_bis = scaler.fit(X_bis_train)\n",
    "\n",
    "# Scale the data\n",
    "X_bis_train_scaled = X_scaler.transform(X_bis_train)\n",
    "X_bis_test_scaled = X_scaler.transform(X_bis_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define, build, train and evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6905 - acc: 0.55490s - loss: 0.6907 - acc: 0.554\n",
      "Epoch 2/100\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6850 - acc: 0.5663\n",
      "Epoch 3/100\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6840 - acc: 0.5679\n",
      "Epoch 4/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6825 - acc: 0.5703\n",
      "Epoch 5/100\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6819 - acc: 0.5709\n",
      "Epoch 6/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6816 - acc: 0.5709\n",
      "Epoch 7/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6814 - acc: 0.5716\n",
      "Epoch 8/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6812 - acc: 0.5739\n",
      "Epoch 9/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6811 - acc: 0.57340s - loss: 0.6819 - acc:  - ETA: 0s - loss: 0.6820 - acc\n",
      "Epoch 10/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6810 - acc: 0.5735\n",
      "Epoch 11/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6806 - acc: 0.5731\n",
      "Epoch 12/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6803 - acc: 0.5742\n",
      "Epoch 13/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6803 - acc: 0.57460s - loss: 0.6800 - acc: 0.\n",
      "Epoch 14/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6803 - acc: 0.5746\n",
      "Epoch 15/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6797 - acc: 0.57710s - loss: 0.6\n",
      "Epoch 16/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6800 - acc: 0.57590s - loss: 0.6799 - acc: 0.576\n",
      "Epoch 17/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6795 - acc: 0.57570s - loss: 0.6796 \n",
      "Epoch 18/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6797 - acc: 0.5760\n",
      "Epoch 19/100\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6794 - acc: 0.57610s - loss: 0.6788 - acc: 0.\n",
      "Epoch 20/100\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6789 - acc: 0.5769\n",
      "Epoch 21/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6790 - acc: 0.5766\n",
      "Epoch 22/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6787 - acc: 0.5753\n",
      "Epoch 23/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6786 - acc: 0.5761\n",
      "Epoch 24/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6787 - acc: 0.5771\n",
      "Epoch 25/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6784 - acc: 0.5779\n",
      "Epoch 26/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6785 - acc: 0.5770\n",
      "Epoch 27/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6783 - acc: 0.5780\n",
      "Epoch 28/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6781 - acc: 0.57820s - loss: 0.6773 - a\n",
      "Epoch 29/100\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6779 - acc: 0.5786\n",
      "Epoch 30/100\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6782 - acc: 0.5781\n",
      "Epoch 31/100\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6777 - acc: 0.5784\n",
      "Epoch 32/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6774 - acc: 0.5787\n",
      "Epoch 33/100\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6777 - acc: 0.5786\n",
      "Epoch 34/100\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6774 - acc: 0.5772\n",
      "Epoch 35/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6770 - acc: 0.5795\n",
      "Epoch 36/100\n",
      "25716/25716 [==============================] - ETA: 0s - loss: 0.6770 - acc: 0.578 - 1s 30us/sample - loss: 0.6770 - acc: 0.5789\n",
      "Epoch 37/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6766 - acc: 0.57940s - loss: 0.6763 - acc\n",
      "Epoch 38/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6768 - acc: 0.5799\n",
      "Epoch 39/100\n",
      "25716/25716 [==============================] - 1s 29us/sample - loss: 0.6766 - acc: 0.5807\n",
      "Epoch 40/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6763 - acc: 0.58010s - loss: 0.6744 - \n",
      "Epoch 41/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6763 - acc: 0.5797\n",
      "Epoch 42/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6764 - acc: 0.5809\n",
      "Epoch 43/100\n",
      "25716/25716 [==============================] - 1s 37us/sample - loss: 0.6761 - acc: 0.5804\n",
      "Epoch 44/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6758 - acc: 0.5803\n",
      "Epoch 45/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6758 - acc: 0.57940s - loss: 0.6759 - acc: 0.57\n",
      "Epoch 46/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6759 - acc: 0.5814\n",
      "Epoch 47/100\n",
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6757 - acc: 0.5809\n",
      "Epoch 48/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6756 - acc: 0.5816\n",
      "Epoch 49/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6754 - acc: 0.5799\n",
      "Epoch 50/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6755 - acc: 0.5805\n",
      "Epoch 51/100\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6752 - acc: 0.5810\n",
      "Epoch 52/100\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6753 - acc: 0.5810\n",
      "Epoch 53/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6753 - acc: 0.5809\n",
      "Epoch 54/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6753 - acc: 0.5802\n",
      "Epoch 55/100\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6749 - acc: 0.5814\n",
      "Epoch 56/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6750 - acc: 0.5812\n",
      "Epoch 57/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6748 - acc: 0.5808\n",
      "Epoch 58/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6744 - acc: 0.58240s - loss: 0.6728 - acc:\n",
      "Epoch 59/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6751 - acc: 0.5816\n",
      "Epoch 60/100\n",
      "25716/25716 [==============================] - 1s 36us/sample - loss: 0.6748 - acc: 0.58210s - loss: 0.6732 - ac\n",
      "Epoch 61/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6745 - acc: 0.5814\n",
      "Epoch 62/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6746 - acc: 0.5819\n",
      "Epoch 63/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6745 - acc: 0.58200s - loss: 0.674\n",
      "Epoch 64/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6744 - acc: 0.5808\n",
      "Epoch 65/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6741 - acc: 0.58080s - loss: 0.6714 - acc\n",
      "Epoch 66/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6739 - acc: 0.5823\n",
      "Epoch 67/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6739 - acc: 0.58090s - loss: 0.6733 - acc: - ETA: 0s - loss: 0.6740 - acc: 0\n",
      "Epoch 68/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6738 - acc: 0.58250s - loss: 0.6746 - acc: 0.58\n",
      "Epoch 69/100\n",
      "25716/25716 [==============================] - 1s 39us/sample - loss: 0.6741 - acc: 0.5826\n",
      "Epoch 70/100\n",
      "25716/25716 [==============================] - 1s 35us/sample - loss: 0.6736 - acc: 0.5835\n",
      "Epoch 71/100\n",
      "25716/25716 [==============================] - 1s 34us/sample - loss: 0.6737 - acc: 0.58300s - loss: 0.672\n",
      "Epoch 72/100\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6737 - acc: 0.5824\n",
      "Epoch 73/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6737 - acc: 0.5822\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716/25716 [==============================] - 1s 33us/sample - loss: 0.6737 - acc: 0.5817\n",
      "Epoch 75/100\n",
      "25716/25716 [==============================] - 1s 32us/sample - loss: 0.6734 - acc: 0.5826\n",
      "Epoch 76/100\n",
      "25716/25716 [==============================] - 1s 31us/sample - loss: 0.6735 - acc: 0.5818\n",
      "Epoch 77/100\n",
      "25716/25716 [==============================] - 1s 30us/sample - loss: 0.6730 - acc: 0.5821\n",
      "Epoch 78/100\n",
      "25716/25716 [==============================] - 1s 38us/sample - loss: 0.6734 - acc: 0.5836\n",
      "Epoch 79/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6731 - acc: 0.5824\n",
      "Epoch 80/100\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6734 - acc: 0.5822\n",
      "Epoch 81/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6730 - acc: 0.5832\n",
      "Epoch 82/100\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6730 - acc: 0.5840\n",
      "Epoch 83/100\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6730 - acc: 0.5828\n",
      "Epoch 84/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6728 - acc: 0.5819\n",
      "Epoch 85/100\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6727 - acc: 0.5842\n",
      "Epoch 86/100\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6725 - acc: 0.5836\n",
      "Epoch 87/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6726 - acc: 0.5826\n",
      "Epoch 88/100\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6726 - acc: 0.5830\n",
      "Epoch 89/100\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6726 - acc: 0.5825\n",
      "Epoch 90/100\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6726 - acc: 0.5836\n",
      "Epoch 91/100\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6725 - acc: 0.5832\n",
      "Epoch 92/100\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6723 - acc: 0.5840\n",
      "Epoch 93/100\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6728 - acc: 0.5819\n",
      "Epoch 94/100\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6723 - acc: 0.5828\n",
      "Epoch 95/100\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6724 - acc: 0.5823\n",
      "Epoch 96/100\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6724 - acc: 0.5833\n",
      "Epoch 97/100\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6722 - acc: 0.5837\n",
      "Epoch 98/100\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6728 - acc: 0.5840\n",
      "Epoch 99/100\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6722 - acc: 0.5826\n",
      "Epoch 100/100\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6727 - acc: 0.5833\n",
      "8573/8573 - 0s - loss: 0.6963 - acc: 0.5604\n",
      "Loss: 0.6963099158659819, Accuracy: 0.5603639483451843\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_bis_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_bis_train_scaled[0])*3\n",
    "hidden_nodes_layer2 = len(X_bis_train_scaled[0])\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_bis_train_scaled, y_bis_train, epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_bis_test_scaled,y_bis_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
